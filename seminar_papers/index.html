<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.3.0 for Hugo"><meta name=description content><link rel=alternate hreflang=en-us href=https://bspl.korea.ac.kr/seminar_papers/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#1565c0"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.d4217de0a97b753d87af942d59c81115.css><link rel=alternate href=/seminar_papers/index.xml type=application/rss+xml title="Brain Signal Processing Lab"><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu746e86b219933ead05b970d8e60fbf48_161589_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu746e86b219933ead05b970d8e60fbf48_161589_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://bspl.korea.ac.kr/seminar_papers/><meta property="twitter:card" content="summary"><meta property="og:site_name" content="Brain Signal Processing Lab"><meta property="og:url" content="https://bspl.korea.ac.kr/seminar_papers/"><meta property="og:title" content="Seminar Papers | Brain Signal Processing Lab"><meta property="og:description" content><meta property="og:image" content="https://bspl.korea.ac.kr/media/icon_hu746e86b219933ead05b970d8e60fbf48_161589_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="https://bspl.korea.ac.kr/media/icon_hu746e86b219933ead05b970d8e60fbf48_161589_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2024-11-27T00:00:00+00:00"><title>Seminar Papers | Brain Signal Processing Lab</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=1ef0c7c24519ec8ae8f7b9f6b71a9a5f><script src=/js/wowchemy-init.min.1d309c6b3f55725f8869af2651084961.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Brain Signal Processing Lab</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Brain Signal Processing Lab</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/aims><span>BSPL is..</span></a></li><li class=nav-item><a class=nav-link href=/members><span>Members</span></a></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Publications</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/publications/articles><span>Articles</span></a>
<a class=dropdown-item href=/publications/domestic_conferences><span>Domestic Conferences</span></a>
<a class=dropdown-item href=/publications/international_conferences><span>International Conferences</span></a></div></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Softwares</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/softwares/dnn><span>DNN</span></a>
<a class=dropdown-item href=/softwares/idr><span>iDR</span></a>
<a class=dropdown-item href=/softwares/rspca><span>rsPCA</span></a>
<a class=dropdown-item href=/softwares/env><span>ENV</span></a>
<a class=dropdown-item href=https://github.com/bsplku><span>GitHub</span></a></div></li><li class=nav-item><a class="nav-link active" href=/seminar_papers><span>Seminar Papers</span></a></li><li class=nav-item><a class=nav-link href=/news><span>Lab News</span></a></li><li class=nav-item><a class=nav-link href=/contact><span>Contact Us</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><div class="universal-wrapper pt-3"><h1>Seminar Papers</h1></div><div class=universal-wrapper><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2024_11_27_ogedegbe_et_al_cardiology_clinics_lin_et_al_physiological_measurement_ding_et_al_scientific_reports/>[Article] Principles and Techniques of Blood Pressure Measurement & Investigating the physiological mechanisms of the photoplethysmogram features for blood pressure estimation & Pulse Transit Time Based Continuous Cuffless Blood Pressure Estimation: A New Extension and A Comprehensive Evaluation.</a></div><div class=mt-2><h3 id=principles-and-techniques-of-blood-pressure-measurement>Principles and Techniques of Blood Pressure Measurement</h3><p>Summary: The first study reviews the principles and techniques of blood pressure (BP) measurement, emphasizing the importance of accurate methods for clinical and research applications. It discusses various BP measurement techniques, including auscultatory, oscillometric, and ambulatory methods, and highlights potential sources of error and strategies to minimize them.</p><p><a href=https://www.cardiology.theclinics.com/article/S0733-8651%2810%2900086-X/abstract target=_blank rel=noopener>Ogedegbe, G., & Pickering, T. (2010). Principles and techniques of blood pressure measurement. Cardiology clinics, 28(4), 571-586.</a></p><h3 id=investigating-the-physiological-mechanisms-of-the-photoplethysmogram-features-for-blood-pressure-estimation>Investigating the physiological mechanisms of the photoplethysmogram features for blood pressure estimation</h3><p>Summary: The second study examines the physiological basis of PPG features for BP estimation by analyzing 65 features from 12 healthy subjects during cold stimuli and exercise recovery.</p><p><a href=https://iopscience.iop.org/article/10.1088/1361-6579/ab7d78/meta target=_blank rel=noopener>Lin, W. H., Li, X., Li, Y., Li, G., & Chen, F. (2020). Investigating the physiological mechanisms of the photoplethysmogram features for blood pressure estimation. Physiological measurement, 41(4), 044003.</a></p><h3 id=pulse-transit-time-based-continuous-cuffless-blood-pressure-estimation-a-new-extension-and-a-comprehensive-evaluation>Pulse Transit Time Based Continuous Cuffless Blood Pressure Estimation: A New Extension and A Comprehensive Evaluation</h3><p>Summary: The third study demonstrates a cuffless BP measurement method combining PTT and the novel PPG intensity ratio (PIR).</p><p><a href=https://www.nature.com/articles/s41598-017-11507-3/1000 target=_blank rel=noopener>Ding, X., Yan, B. P., Zhang, Y. T., Liu, J., Zhao, N., & Tsang, H. K. (2017). Pulse transit time based continuous cuffless blood pressure estimation: A new extension and a comprehensive evaluation. Scientific reports,
7(1), 1-11.</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Nov 27, 2024</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2024_11_13_karakose-akbiyik_nature_communications_mcmahon_current_biology/>[Article] Hierarchical organization of social action features along the lateral visual pathway</a></div><div class=mt-2><p>summary: The first study investigates the hierarchical organization of social action features along the lateral visual stream, revealing that the brain processes increasingly complex features, from low-level motion in early visual areas to high-level communicative actions in the superior temporal sulcus (STS). The second study demonstrates a shared neural code for representing both human actions and object events, suggesting that the brain uses a common neural mechanism to interpret the physics of interactions, independent of animacy. Together, these findings provide new insights into the neural architecture underlying social perception and event understanding, highlighting both specialized and generalized processes in the human brain.</p><p>Karakose-Akbiyik, Seda, Alfonso Caramazza, and Moritz F. Wurm. &ldquo;A shared neural code for the physics of actions and object events.&rdquo; Nature Communications 14.1 (2023): 3316. <a href=//bspl.korea.ac.kr/Board/Members_Only/Lab_Seminar/KJE/Karakose-Akbiyik_et_al_2023.pdf>(link)</a></p><p>McMahon, Emalie, Michael F. Bonner, and Leyla Isik. &ldquo;Hierarchical organization of social action features along the lateral visual pathway.&rdquo; Current Biology 33.23 (2023): 5035-5047. <a href=//bspl.korea.ac.kr/Board/Members_Only/Lab_Seminar/KJE/McMahon_et_al_2023.pdf>(link)</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Nov 13, 2024</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2024_10_02_ljhyeon_rsa/>[Session] Exploring brain-to-model similarities with representational similarity analysis (RSA).</a></div><div class=mt-2><p>[LJHyeon (PhD). Exploring brain-to-model similarities with representational similarity analysis (RSA)]</p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Oct 2, 2024</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2024_09_11_giannakakis_et_al_ieee/>[Article] Review on Psychological Stress Detection Using Biosignals. IEEE Transactions on Affective Computing.</a></div><div class=mt-2><p>Summary: This paper provides a comprehensive overview of how psychological stress can be detected through various biosignals. It discusses the physiological processes triggered by stress, which are measurable through signals like EEG, ECG, EDA, and others(7 more bio-signals). The paper aims to establish reliable biosignal indices that can effectively indicate stress levels, emphasizing the need for consistency and robustness in biosignal data features.</p><p><a href=https://ieeexplore.ieee.org/abstract/document/8758154/ target=_blank rel=noopener>Giannakakis, Giorgos, et al. &ldquo;Review on psychological stress detection using biosignals.&rdquo; IEEE transactions on affective computing 13.1 (2019): 440-460.</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Sep 11, 2024</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2024_08_29_cruz_et_al_ieee/>[Article] Eye-lrcn: A long-term recurrent convolutional network for eye blink completeness detection. IEEE Transactions on Neural Networks and Learning Systems.</a></div><div class=mt-2><p>Summary: The article introduces Eye-LRCN, a new method for eye blink detection that also evaluates blink completeness using a Long-Term Recurrent Convolutional Network (LRCN). This approach combines a CNN for feature extraction with a bidirectional RNN for sequence learning, and employs a Siamese architecture to handle class imbalance and limited data. Eye-LRCN demonstrates superior performance in blink detection and completeness assessment, and achieves noticeable results in eye state detection.</p><p><a href=https://ieeexplore.ieee.org/abstract/document/9885029 target=_blank rel=noopener>de la Cruz, Gonzalo, et al. &ldquo;Eye-lrcn: A long-term recurrent convolutional network for eye blink completeness detection.&rdquo; IEEE Transactions on Neural Networks and Learning Systems 35.4 (2022): 5130-5140.</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Aug 29, 2024</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2024_08_14_menon_neuron/>[Article] 20 years of the default mode network: A review and synthesis. Neuron.</a></div><div class=mt-2><p>Summary: The author thoroughly reviewed organization of the default mode network (DMN) and cognitive roles of the DMN (i.e., self-reference, social cognition, memory, mind wandering). Finally, he suggested a new perspective of the DMN function in human cognitition, in which the DMN intergrate and &ldquo;broadcast&rdquo; various representations to create coherent &ldquo;interal narrative&rdquo;.</p><p><a href=https://www.sciencedirect.com/science/article/pii/S0896627323003082 target=_blank rel=noopener>Menon, V. (2023). 20 years of the default mode network: A review and synthesis. Neuron.</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Aug 14, 2024</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2024_07_31_kumar_et_al_nature_communication/>[Article] Shared functional specialization in transformer-based language models and the human brain.</a></div><div class=mt-2><p>Summary: Transformers are recently being compared to the brain. Usually, the internal representations (“embeddings”) are adopted for comparisons. However, the authors focused on “transformations” that integrate contextual information across words, and found that they are more layer-specific than the embeddings. It differs from existing research in that it focuses on transformations related to attention instead of embeddings, which has been one of our recent interests.</p><p><a href=https://www.nature.com/articles/s41467-024-49173-5 target=_blank rel=noopener>Kumar, S., Sumers, T. R., Yamakoshi, T., Goldstein, A., Hasson, U., Norman, K. A., &mldr; & Nastase, S. A. (2024). Shared functional specialization in transformer-based language models and the human brain. Nature Communications, 15(1), 5523.</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Jul 31, 2024</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2024_06_19_caro_et_al_biorxiv/>[Article] BrainLM: A foundation model for brain activity recordings</a></div><div class=mt-2><h3 id=brainlm-a-foundation-model-for-brain-activity-recordings>BrainLM: A foundation model for brain activity recordings</h3><p>Summary: This paper suggested BrainLM which is a foundation model for brain activity dynamics trained on 6,700 hours of fMRI recordings.</p><p><a href=https://www.biorxiv.org/content/10.1101/2023.09.12.557460v2.full target=_blank rel=noopener>Ortega Caro, Josue, et al. &ldquo;BrainLM: A foundation model for brain activity recordings.&rdquo; bioRxiv (2023): 2023-09.</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Jun 19, 2024</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2024_06_17_xiew_et_al_nature_medicine/>[Article] A shared neural basis underlying psychiatric comorbidity.</a></div><div class=mt-2><p>Summary: Utilizing large longitudinal neuroimaging cohort (from adolescence to young adulthood) (IMAGEN), they use multitask connectomes to find neuropsychopathological (NP) factor. They also check generalizability of the NP factor with ABCD (and other) datasets.</p><p><a href=https://www.nature.com/articles/s41591-023-02317-4 target=_blank rel=noopener>Xie, C., Xiang, S., Shen, C., Peng, X., Kang, J., Li, Y., &mldr; & ZIB Consortium. (2023). A shared neural basis underlying psychiatric comorbidity. Nature medicine, 29(5), 1232-1242.</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Jun 17, 2024</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2024_06_05_chaiebleila_et_al_frontiers_in_psychiatry/>[Article] Auditory beat stimulation and its effects on cognition and mood states.</a></div><div class=mt-2><p>Summary: This paper presents a comprehensive review of auditory beat stimulation, with a particular focus on the applications and features of binaural beats. Despite the extensive research conducted on binaural beats, there is still a lack of consensus regarding the consistent effects and the underlying neural mechanisms.</p><p><a href=https://www.frontiersin.org/journals/psychiatry/articles/10.3389/fpsyt.2015.00070/full target=_blank rel=noopener>Chaieb, Leila, et al. &ldquo;Auditory beat stimulation and its effects on cognition and mood states.&rdquo; Frontiers in psychiatry 6 (2015): 136819.</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Jun 5, 2024</span></div></div></div><div class=ml-3></div></div><nav class=mt-1><ul class="pagination justify-content-center"><li class=page-item><a class=page-link href=/seminar_papers/page/2/>&#187;</a></li></ul></nav></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>© 2024 BSPL</p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-modules target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script><script src=/en/js/wowchemy.min.e762603fd04b1d81f1e953bafed73e89.js></script></body></html>