<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.3.0 for Hugo"><meta name=description content><link rel=alternate hreflang=en-us href=https://bspl.korea.ac.kr/seminar_papers/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#1565c0"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.d4217de0a97b753d87af942d59c81115.css><link rel=alternate href=/seminar_papers/index.xml type=application/rss+xml title="Brain Signal Processing Lab"><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu746e86b219933ead05b970d8e60fbf48_161589_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu746e86b219933ead05b970d8e60fbf48_161589_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://bspl.korea.ac.kr/seminar_papers/><meta property="twitter:card" content="summary"><meta property="og:site_name" content="Brain Signal Processing Lab"><meta property="og:url" content="https://bspl.korea.ac.kr/seminar_papers/"><meta property="og:title" content="Interesting Works | Brain Signal Processing Lab"><meta property="og:description" content><meta property="og:image" content="https://bspl.korea.ac.kr/media/icon_hu746e86b219933ead05b970d8e60fbf48_161589_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="https://bspl.korea.ac.kr/media/icon_hu746e86b219933ead05b970d8e60fbf48_161589_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2024-07-31T00:00:00+00:00"><title>Interesting Works | Brain Signal Processing Lab</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=1ef0c7c24519ec8ae8f7b9f6b71a9a5f><script src=/js/wowchemy-init.min.1d309c6b3f55725f8869af2651084961.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Brain Signal Processing Lab</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Brain Signal Processing Lab</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/aims><span>BSPL is..</span></a></li><li class=nav-item><a class=nav-link href=/members><span>Members</span></a></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Publications</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/publications/articles><span>Articles</span></a>
<a class=dropdown-item href=/publications/domestic_conferences><span>Domestic Conferences</span></a>
<a class=dropdown-item href=/publications/international_conferences><span>International Conferences</span></a></div></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Softwares</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/softwares/dnn><span>DNN</span></a>
<a class=dropdown-item href=/softwares/idr><span>iDR</span></a>
<a class=dropdown-item href=/softwares/rspca><span>rsPCA</span></a>
<a class=dropdown-item href=/softwares/env><span>ENV</span></a>
<a class=dropdown-item href=https://github.com/bsplku><span>GitHub</span></a></div></li><li class=nav-item><a class="nav-link active" href=/seminar_papers><span>Seminar Papers</span></a></li><li class=nav-item><a class=nav-link href=/news><span>Lab News</span></a></li><li class=nav-item><a class=nav-link href=/contact><span>Contact Us</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><div class="universal-wrapper pt-3"><h1>Interesting Works</h1></div><div class=universal-wrapper><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2018_02_21_article_deep_learning_for_biology/>[Article] Deep learning for biology</a></div><div class=mt-2><p>A popular artificial-intelligence method provides a powerful tool for surveying and classifying biological data. But for the uninitiated, the technology poses significant difficulties.</p><p><a href=https://www.nature.com/articles/d41586-018-02174-z target=_blank rel=noopener>https://www.nature.com/articles/d41586-018-02174-z</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Feb 21, 2018</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2017_11_06_blog_ccneuro_asks__how_can_we_find_out_how_the_brain_works/>[Blog] #CCNeuro asks: 'How can we find out how the brain works?'</a></div><div class=mt-2><p><strong><a href=http://www.thebrainblog.org/ target=_blank rel=noopener>The Brain Blog</a></strong></p><ul><li>Thoughts and discussion about the brain from Peter Bandettini and Eric Wong</li></ul><p>In this blog, the professor Eric Wong discussed about &ldquo;How can we find out how the brain works?&rdquo;, which is asked from the Cognitive Computational Neuroscience (CCNeuro) conference.</p><p>In short, he mentioned that the most typical conceptual approach to understanding the brain is considering the brain is modular. Thus, the modularity is important for understanding the brain from complexity.</p><p>The more details is shown in the brain blog (<a href=http://www.thebrainblog.org/ target=_blank rel=noopener>www.thebrainblog.org</a>).</p><p>Beside this issues, you could find many neuroscience related thought and discussion from Peter Bandettini and Eric Wong in this blog.</p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Nov 6, 2017</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2017_10_02_article_consciousness_in_the_machine_learning_deep_learning_perspective/>[Article] 'Consciousness' in the machine learning (deep learning) perspective</a></div><div class=mt-2><br>**The Consciousness Prior**<br>Yoshua Bengio<br>Université de Montréal, MILA<br>September 26, 2017<br>**Abstract**<br>A new prior is proposed for representation learning, which canbe combined with other priors in order to help disentangling abstract factorsfrom each other. It is inspired by the phenomenon of conscious-ness seen as theformation of a low-dimensional combination of a few concepts constituting aconscious thought, i.e., consciousness as awareness at a particular timeinstant. This provides a powerful constraint on the representation in that suchlow-dimensional thought vectors can correspond to statements about realitywhich are either true, highly probable, or very useful for taking decisions.The fact that a few elements of the current state can be combined into such apredictive or useful statement is a strong constraint and deviates considerablyfrom the maximum likelihood approaches to modeling data and how states unfoldin the future based on an agent's actions. Instead of making predictions in thesensory (e.g. pixel) space, the consciousness prior allow the agent to makepredictions in the abstract space, with only a few dimensions of that spacebeing involved in each of these predictions. The consciousness prior also makesit natural to map conscious states to natural language utterances or to expressclassical AI knowledge in the form of facts and rules, although the consciousstates may be richer than what can be expressed easily in the form of asentence, a fact or a rule. <p><a href=https://arxiv.org/pdf/1709.08568.pdf target=_blank rel=noopener>https://arxiv.org/pdf/1709.08568.pdf</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Oct 2, 2017</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2017_09_01_news_robotic_system_monitors_specific_neurons/>[NEWS] Robotic system monitors specific neurons</a></div><div class=mt-2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201708/MIT-Neuron-Recording-1_0.jpg?itok=CFz2BscX" alt loading=lazy data-zoomable></div></div></figure></p><p><a href=http://news.mit.edu/2017/robotic-system-monitors-specific-neurons-0830 target=_blank rel=noopener>(from MIT news)</a><br>Recording electrical signals from inside a neuron in the living brain can reveal a great deal of information about that neuron&rsquo;s function and how it coordinates with other cells in the brain. However, performing this kind of recording is extremely difficult, so only a handful of neuroscience labs around the world do it.
To make this technique more widely available, MIT engineers have now devised a way to automate the process, using a computer algorithm that analyzes microscope images and guides a robotic arm to the target cell. This technology could allow more scientists to study single neurons and learn how they interact with other cells to enable cognition, sensory perception, and other brain functions. Researchers could also use it to learn more about how neural circuits are affected by brain disorders.</p><p>If you interested in, please click the following link.</p><p><a href=http://news.mit.edu/2017/robotic-system-monitors-specific-neurons-0830 target=_blank rel=noopener>http://news.mit.edu/2017/robotic-system-monitors-specific-neurons-0830</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Sep 1, 2017</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2017_07_11_news_what_the_brains_wiring_looks_like/>[News] What the brain's wiring looks like</a></div><div class=mt-2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=https://ichef.bbci.co.uk/images/ic/560x315/p057p4pb.jpg alt loading=lazy data-zoomable></div></div></figure></p><p><a href=http://www.bbc.com/news/health-40488545 target=_blank rel=noopener>(from BBC news)</a></p><p><em>The world&rsquo;s most detailed scan of the brain&rsquo;s internal wiring has been produced by scientists at Cardiff University.</em><br>The MRI machine reveals the fibres which carry all the brain&rsquo;s thought processes.
It&rsquo;s been done in Cardiff, Nottingham, Cambridge and Stockport, as well as London England and London Ontario.
Doctors hope it will help increase understanding of a range of neurological disorders and could be used instead of invasive biopsies.
If you interested in, please click the following link.</p><p><a href=http://www.bbc.com/news/health-40488545 target=_blank rel=noopener>http://www.bbc.com/news/health-40488545</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Jul 11, 2017</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2017_07_11_news_peering_into_neural_networks/>[News] Peering into neural networks</a></div><div class=mt-2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201706/MIT-neural-internal_0.jpg?itok=s69bCGos#50" alt loading=lazy data-zoomable></div></div></figure>(Image: Christine Daniloff/MIT)</p><p><em>&ldquo;New technique helps elucidate the inner workings of neural networks trained on visual data&rdquo;</em></p><p>Neural networks is for performing computational tasks by learning. The learning is conducted by analyze large sets of training data. However, it is difficult to recognize which data they are processing between input and output.</p><p>A researchers from Computer Science and Artificial Intelligence Laboratory (CSAIL) of MIT, showed a method to find out the process during training the visual scenes identification. From this study, Bau, one of the researcher of this study, mentioned that it suggests that &ldquo;neural networks are actually trying to approximate getting a grandmother neuron&rdquo;.</p><p>If you interested in, please click the following link.</p><p><a href=http://news.mit.edu/2017/inner-workings-neural-networks-visual-data-0630 target=_blank rel=noopener>http://news.mit.edu/Peering_into_neural_networks</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Jul 11, 2017</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2017_05_02_news_scientists_identify_brain_circuit_that_drives_pleasure-inducing_behavior/>[NEWS] Scientists identify brain circuit that drives pleasure-inducing behavior</a></div><div class=mt-2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201703/MIT-Appetite-Control_0.jpg?itok=vgyHPujC#50" alt loading=lazy data-zoomable></div></div></figure></p><p>(from MIT news)</p><p>Scientists have long believed that the central amygdala, a structure located deep within the brain, is linked with fear and responses to unpleasant events.
However, a team of MIT neuroscientists has now discovered a circuit in this structure that responds to rewarding events. In a study of mice, activating this circuit with certain stimuli made the animals seek those stimuli further. The researchers also found a circuit that controls responses to fearful events, but most of the neurons in the central amygdala are involved in the reward circuit, they report.</p><p>If you are interested in, please click following link :</p><p><a href=http://news.mit.edu/2017/brain-circuit-pleasure-inducing-behavior-0322 target=_blank rel=noopener>http://news.mit.edu/2017/brain-circuit-pleasure-inducing-behavior-0322</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>May 2, 2017</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2017_03_20_news_brain-controlled_robots/>[NEWS] Brain-controlled robots</a></div><div class=mt-2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201703/brain-waves-EEG-MIT-CSAIL-00_1.jpg?itok=1jJBX7DC#50" alt loading=lazy data-zoomable></div></div></figure></p><p>(from MIT news)</p><p>For robots to do what we want, they need to understand us. Too often, this means having to meet them halfway: teaching them the intricacies of human language, for example, or giving them explicit commands for very specific tasks.
But what if we could develop robots that were a more natural extension of us and that could actually do whatever we are thinking?
A team from MIT&rsquo;s Computer Science and Artificial Intelligence Laboratory (CSAIL) and Boston University is working on this problem, creating a feedback system that lets people correct robot mistakes instantly with nothing more than their brains.
Using data from an electroencephalography (EEG) monitor that records brain activity, the system can detect if a person notices an error as a robot performs an object-sorting task. The team&rsquo;s novel machine-learning algorithms enable the system to classify brain waves in the space of 10 to 30 milliseconds.</p><p>If you are interested in, please click below.</p><p><a href=http://news.mit.edu/2017/brain-controlled-robots-0306 target=_blank rel=noopener>http://news.mit.edu/2017/brain-controlled-robots-0306</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Mar 20, 2017</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2017_02_28_news_sensor_traces_dopamine_released_by_single_cells/>[NEWS] Sensor traces dopamine released by single cells</a></div><div class=mt-2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201702/MIT-Dope-Sense_0.jpg?itok=IQ48aknq#50" alt loading=lazy data-zoomable></div></div></figure>(from MIT news)</p><p>MIT chemical engineers have developed an extremely sensitive detector that can track single cells&rsquo; secretion of dopamine, a brain chemical responsible for carrying messages involved in reward-motivated behavior, learning, and memory. Using arrays of up to 20,000 tiny sensors, the researchers can monitor dopamine secretion of single neurons, allowing them to explore critical questions about dopamine dynamics. Until now, that has been very difficult to do.</p><p>Strano and his colleagues have already demonstrated that dopamine release occurs differently than scientists expected in a type of neural progenitor cell, helping to shed light on how dopamine may exert its effects in the brain.</p><p>If you are interested in, please click following link:</p><p><a href=http://news.mit.edu/2017/sensor-traces-dopamine-released-single-cells-0206 target=_blank rel=noopener>http://news.mit.edu/2017/sensor-traces-dopamine-released-single-cells-0206</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Feb 28, 2017</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2017_02_12_award_best_poster_paper_award_besk_workshop_2017_feb._09/>[Award] Best Poster Paper Award, BESK Workshop 2017 (Feb. 09)</a></div><div class=mt-2><p>Award winner: Hyun-Chul Kim</p><p>Poster title: <a href=/publications/domestic_conferences/2017_02_06_emotion_prediction_from_the_fmri_data_using_deep_neural_network/>Emotion prediction from the fMRI data using deep neural network</a></p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://bspl.korea.ac.kr/Board/General/best_poster_paper_award_KHC.png alt loading=lazy data-zoomable></div></div></figure></p><p>Many congratulations!</p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Feb 12, 2017</span></div></div></div><div class=ml-3></div></div><nav class=mt-1><ul class="pagination justify-content-center"><li class=page-item><a class=page-link href=/seminar_papers/page/8/>&#171;</a></li><li class=page-item><a class=page-link href=/seminar_papers/page/10/>&#187;</a></li></ul></nav></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>© 2024 BSPL</p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-modules target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script><script src=/en/js/wowchemy.min.e762603fd04b1d81f1e953bafed73e89.js></script></body></html>