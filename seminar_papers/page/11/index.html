<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.3.0 for Hugo"><meta name=description content><link rel=alternate hreflang=en-us href=https://bspl.korea.ac.kr/seminar_papers/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#1565c0"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.d4217de0a97b753d87af942d59c81115.css><link rel=alternate href=/seminar_papers/index.xml type=application/rss+xml title="Brain Signal Processing Lab"><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu746e86b219933ead05b970d8e60fbf48_161589_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu746e86b219933ead05b970d8e60fbf48_161589_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://bspl.korea.ac.kr/seminar_papers/><meta property="twitter:card" content="summary"><meta property="og:site_name" content="Brain Signal Processing Lab"><meta property="og:url" content="https://bspl.korea.ac.kr/seminar_papers/"><meta property="og:title" content="Seminar Papers | Brain Signal Processing Lab"><meta property="og:description" content><meta property="og:image" content="https://bspl.korea.ac.kr/media/icon_hu746e86b219933ead05b970d8e60fbf48_161589_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="https://bspl.korea.ac.kr/media/icon_hu746e86b219933ead05b970d8e60fbf48_161589_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2025-01-14T00:00:00+00:00"><title>Seminar Papers | Brain Signal Processing Lab</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=1ef0c7c24519ec8ae8f7b9f6b71a9a5f><script src=/js/wowchemy-init.min.1d309c6b3f55725f8869af2651084961.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Brain Signal Processing Lab</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Brain Signal Processing Lab</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/aims><span>BSPL is..</span></a></li><li class=nav-item><a class=nav-link href=/members><span>Members</span></a></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Publications</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/publications/articles><span>Articles</span></a>
<a class=dropdown-item href=/publications/domestic_conferences><span>Domestic Conferences</span></a>
<a class=dropdown-item href=/publications/international_conferences><span>International Conferences</span></a></div></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Softwares</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/softwares/dnn><span>DNN</span></a>
<a class=dropdown-item href=/softwares/idr><span>iDR</span></a>
<a class=dropdown-item href=/softwares/rspca><span>rsPCA</span></a>
<a class=dropdown-item href=/softwares/env><span>ENV</span></a>
<a class=dropdown-item href=https://github.com/bsplku><span>GitHub</span></a></div></li><li class=nav-item><a class="nav-link active" href=/seminar_papers><span>Seminar Papers</span></a></li><li class=nav-item><a class=nav-link href=/news><span>Lab News</span></a></li><li class=nav-item><a class=nav-link href=/contact><span>Contact Us</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><div class="universal-wrapper pt-3"><h1>Seminar Papers</h1></div><div class=universal-wrapper><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2017_03_20_news_brain-controlled_robots/>[NEWS] Brain-controlled robots</a></div><div class=mt-2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201703/brain-waves-EEG-MIT-CSAIL-00_1.jpg?itok=1jJBX7DC#50" alt loading=lazy data-zoomable></div></div></figure></p><p>(from MIT news)</p><p>For robots to do what we want, they need to understand us. Too often, this means having to meet them halfway: teaching them the intricacies of human language, for example, or giving them explicit commands for very specific tasks.
But what if we could develop robots that were a more natural extension of us and that could actually do whatever we are thinking?
A team from MIT&rsquo;s Computer Science and Artificial Intelligence Laboratory (CSAIL) and Boston University is working on this problem, creating a feedback system that lets people correct robot mistakes instantly with nothing more than their brains.
Using data from an electroencephalography (EEG) monitor that records brain activity, the system can detect if a person notices an error as a robot performs an object-sorting task. The team&rsquo;s novel machine-learning algorithms enable the system to classify brain waves in the space of 10 to 30 milliseconds.</p><p>If you are interested in, please click below.</p><p><a href=http://news.mit.edu/2017/brain-controlled-robots-0306 target=_blank rel=noopener>http://news.mit.edu/2017/brain-controlled-robots-0306</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Mar 20, 2017</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2017_02_28_news_sensor_traces_dopamine_released_by_single_cells/>[NEWS] Sensor traces dopamine released by single cells</a></div><div class=mt-2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201702/MIT-Dope-Sense_0.jpg?itok=IQ48aknq#50" alt loading=lazy data-zoomable></div></div></figure>(from MIT news)</p><p>MIT chemical engineers have developed an extremely sensitive detector that can track single cells&rsquo; secretion of dopamine, a brain chemical responsible for carrying messages involved in reward-motivated behavior, learning, and memory. Using arrays of up to 20,000 tiny sensors, the researchers can monitor dopamine secretion of single neurons, allowing them to explore critical questions about dopamine dynamics. Until now, that has been very difficult to do.</p><p>Strano and his colleagues have already demonstrated that dopamine release occurs differently than scientists expected in a type of neural progenitor cell, helping to shed light on how dopamine may exert its effects in the brain.</p><p>If you are interested in, please click following link:</p><p><a href=http://news.mit.edu/2017/sensor-traces-dopamine-released-single-cells-0206 target=_blank rel=noopener>http://news.mit.edu/2017/sensor-traces-dopamine-released-single-cells-0206</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Feb 28, 2017</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2017_02_12_award_best_poster_paper_award_besk_workshop_2017_feb._09/>[Award] Best Poster Paper Award, BESK Workshop 2017 (Feb. 09)</a></div><div class=mt-2><p>Award winner: Hyun-Chul Kim</p><p>Poster title: <a href=/publications/domestic_conferences/2017_02_06_emotion_prediction_from_the_fmri_data_using_deep_neural_network/>Emotion prediction from the fMRI data using deep neural network</a></p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://bspl.korea.ac.kr/Board/General/best_poster_paper_award_KHC.png alt loading=lazy data-zoomable></div></div></figure></p><p>Many congratulations!</p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Feb 12, 2017</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2017_02_10_news_better_wisdom_from_crowds/>[News] Better wisdom from crowds</a></div><div class=mt-2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201701/MIT-GroupWisdom_2.jpg?itok=1qKWkpWu#50" alt loading=lazy data-zoomable></div></div></figure></p><p>(from MIT news)</p><p>The wisdom of crowds is not always perfect. But two scholars at MIT&rsquo;s Sloan Neuroeconomics Lab, along with a colleague at Princeton University, have found a way to make it better.
Their method, explained in a newly published paper, uses a technique the researchers call the &ldquo;surprisingly popular&rdquo; algorithm to better extract correct answers from large groups of people. As such, it could refine wisdom-of-crowds surveys, which are used in political and economic forecasting, as well as many other collective activities, from pricing artworks to grading scientific research proposals.</p><p>If you are interested in, please click the following link.</p><p><a href=http://news.mit.edu/2017/algorithm-better-wisdom-crowds-0125 target=_blank rel=noopener>http://news.mit.edu/2017/algorithm-better-wisdom-crowds-0125</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Feb 10, 2017</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2017_01_16_news_a_glimpse_into_the_workings_of_the_baby_brain/>[News] A glimpse into the workings of the baby brain</a></div><div class=mt-2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201701/MIT-Infant-MRI-01.jpg?itok=3MKN-5qo#50" alt loading=lazy data-zoomable></div></div></figure></p><p>(from MIT news)</p><p>In adults, certain regions of the brain&rsquo;s visual cortex respond preferentially to specific types of input, such as faces or objects &mdash; but how and when those preferences arise has long puzzled neuroscientists. One way to help answer that question is to study the brains of very young infants and compare them to adult brains. However, scanning the brains of awake babies in an MRI machine has proven difficult. Now, neuroscientists at MIT have overcome that obstacle, adapting their MRI scanner to make it easier to scan infants&rsquo; brains as the babies watch movies featuring different types of visual input. Using these data, the team found that in some ways, the organization of infants&rsquo; brains is surprisingly similar to that of adults. Specifically, brain regions that respond to faces in adults do the same in babies, as do regions that respond to scenes.</p><p>If you&rsquo;re interested in, please click here,</p><p><a href=http://news.mit.edu/2017/mri-scans-baby-brain-visual-cortex-0110 target=_blank rel=noopener>http://news.mit.edu/2017/mri-scans-baby-brain-visual-cortex-0110</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Jan 16, 2017</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2016_12_26_news_a_delicate_balance_between_positive_and_negative_emotion/>[News] A delicate balance between positive and negative emotion</a></div><div class=mt-2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201610/MIT-emo-balance_0.jpg?itok=BoC1Y85I#50" alt loading=lazy data-zoomable></div></div></figure></p><p>(figure from MITnew)</p><p>Our emotional state is governed partly by a tiny brain structure known as the amygdala, which is responsible for processing positive emotions such as happiness, and negative ones such as fear and anxiety.</p><p>A new study from MIT finds that these emotions are controlled by two populations of neurons that are genetically programmed to encode memories of either fearful or pleasurable events. Furthermore, these sets of cells inhibit each other, suggesting that an imbalance between these populations may be responsible for disorders such as depression and post-traumatic stress disorder.</p><p>If you&rsquo;re interested in, please click here.</p><p><a href=http://news.mit.edu/2016/two-neuron-populations-encode-happy-fearful-memories-1017 target=_blank rel=noopener>http://news.mit.edu/2016/two-neuron-populations-encode-happy-fearful-memories-1017</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Dec 26, 2016</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2016_12_05_news_a_radiation-free_approach_to_imaging_molecules_in_the_brain/>[News] A radiation-free approach to imaging molecules in the brain</a></div><div class=mt-2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201612/MIT-Molecular-Imaging_0.jpg?itok=e_ulBB3p#50" alt loading=lazy data-zoomable></div></div></figure></p><p>(figure from MIT news)</p><p>Scientists hoping to get a glimpse of molecules that control brain activity have devised a new probe that allows them to image these molecules without using any chemical or radioactive labels. Currently the gold standard approach to imaging molecules in the brain is to tag them with radioactive probes. However, these probes offer low resolution and they can&rsquo;t easily be used to watch dynamic events, says Alan Jasanoff, an MIT professor of biological engineering and brain and cognitive sciences.</p><p>Jasanoff and his colleagues have developed new sensors consisting of proteins designed to detect a particular target, which causes them to dilate blood vessels in the immediate area. This produces a change in blood flow that can be imaged with magnetic resonance imaging (MRI) or other imaging techniques.</p><p>If you&rsquo;re interested in,
please click the following link.</p><p><a href=http://news.mit.edu/2016/radiation-free-approach-imaging-molecules-brain-mri-1202 target=_blank rel=noopener>http://news.mit.edu/2016/radiation-free-approach-imaging-molecules-brain-mri-1202</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Dec 5, 2016</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2016_11_21_news_where_music_and_technology_unite/>[News] Where music and technology unite</a></div><div class=mt-2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201611/founder-journey-zolot-mit.jpg?itok=pm53JcdV#50" alt loading=lazy data-zoomable></div></div></figure></p><p>(figure from MIT news)</p><p>In Developing Technologies for Music and Health, students design and prototype devices that explore music&rsquo;s impact on health and brain functions, such as sleep, anxiety, athletic performance, pain, and even dementia. Music therapy is a well-established field, but the idea of integrating technology and data analysis into music therapy to improve a person&rsquo;s well-being is where the future lies. The therapeutic, clinical, and technical applications of music in health are far-reaching, and our ever-connected world presents an exciting opportunity for the young entrepreneur.</p><p>If you&rsquo;re interested in,
please click the following link.</p><p><a href=http://news.mit.edu/2016/where-music-and-technology-unite-1103 target=_blank rel=noopener>http://news.mit.edu/2016/where-music-and-technology-unite-1103</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Nov 21, 2016</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2016_11_03_news_mapping_serotonin_dynamics_in_the_living_brain/>[News] Mapping serotonin dynamics in the living brain</a></div><div class=mt-2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201610/MIT-Mapping-Serotonin_0.jpg?itok=xE6o6oDY#50" alt loading=lazy data-zoomable></div></div></figure></p><p>(Figure from MIT news)</p><p>Serotonin is a neurotransmitter that&rsquo;s partly responsible for feelings of happiness and for mood regulation in humans. This makes it a common target for antidepressants, which block serotonin from being reabsorbed by neurons after it has dispatched its signal, so more of it stays floating around the brain.</p><p>MIT researchers have developed an imaging technique that, for the first time, enables three-dimensional mapping of serotonin as it&rsquo;s reabsorbed into neurons, across multiple regions of the living brain. This technique, the researchers say, gives an unprecedented view of serotonin dynamics, and could be a powerful tool for the research and development of antidepressants.</p><p>If you are interested in, please click the following link.</p><p><a href=http://news.mit.edu/2016/mapping-serotonin-dynamics-living-brain-1020 target=_blank rel=noopener>http://news.mit.edu/2016/mapping-serotonin-dynamics-living-brain-1020</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Nov 3, 2016</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/seminar_papers/2016_10_13_news_monitoring_parkinsons_symptoms_at_home/>[News] Monitoring Parkinson's symptoms at home</a></div><div class=mt-2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201610/MIT-Typing-Parkinsons_0.jpg?itok=gjVblHXH#50" alt loading=lazy data-zoomable></div></div></figure></p><p>(Figure from MIT news)</p><p>Parkinson&rsquo;s disease is the second most common neurodegenerative disorder in the developed world, with around 60,000 people diagnosed in the U.S. each year. Although there is no cure for the disease, there are treatments that can reduce the severity of a patient&rsquo;s symptoms. But for these treatments to be effective, clinicians need a method to regularly monitor the patient&rsquo;s symptoms in the home.</p><p>In a paper published today in the journal <em>Scientific Reports</em>, researchers at MIT and elsewhere describe a technique they have developed to monitor Parkinson&rsquo;s disease progression as patients interact with a computer keyboard.</p><p>If you are interested in, please click the following link</p><p><a href=http://news.mit.edu/2016/keyboard-monitoring-parkinsons-symptoms-1005 target=_blank rel=noopener>http://news.mit.edu/2016/keyboard-monitoring-parkinsons-symptoms</a></p></div><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Oct 13, 2016</span></div></div></div><div class=ml-3></div></div><nav class=mt-1><ul class="pagination justify-content-center"><li class=page-item><a class=page-link href=/seminar_papers/page/10/>&#171;</a></li><li class=page-item><a class=page-link href=/seminar_papers/page/12/>&#187;</a></li></ul></nav></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>© 2025 BSPL</p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-modules target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script><script src=/en/js/wowchemy.min.e762603fd04b1d81f1e953bafed73e89.js></script></body></html>