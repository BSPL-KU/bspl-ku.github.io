---
title: "[Article] Transformer-based multimodal information fusion for facial expression analysis."
date: 2023-04-26
---

summary : In this work, they utilize multimodal features of spoken words, speech prosody and facial expression from Aff-WIld2 dataset. They combine these features using a transformer-based fusion module which makes the output embedding features of sequences of images, audio and text. Integrated output feature is then processed in MLP layer for Action Unit (AU) detection and also facial expression recognition.

[Zhang, Wei, et al. "Transformer-based multimodal information fusion for facial expression analysis." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.](https://openaccess.thecvf.com/content/CVPR2022W/ABAW/papers/Zhang_Transformer-Based_Multimodal_Information_Fusion_for_Facial_Expression_Analysis_CVPRW_2022_paper.pdf)


---
title: "[Article] Video-based multimodal spontaneous emotion recognition using facial expressions and physiological signals."
date: 2023-04-26
---

summary : In this work, they propose the first video-based multimodal spontaneous emotion recognition that combines facial expressions with physiological data to derive the advantages of each modality. The feature vector of facial expression is fused with physiological signals including iPPG signal and HRV. The feature-level fusioned input is then processed in a 3D Xception-net based DNN model.

[Ouzar, Yassine, et al. "Video-based multimodal spontaneous emotion recognition using facial expressions and physiological signals." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.](https://openaccess.thecvf.com/content/CVPR2022W/ABAW/papers/Ouzar_Video-Based_Multimodal_Spontaneous_Emotion_Recognition_Using_Facial_Expressions_and_Physiological_CVPRW_2022_paper.pdf)

