---
title: "[Article] MindLLM: A Subject-Agnostic and Versatile Model for fMRI-to-Text Decoding & Generative language reconstruction from brain recordings & CorText-AMA: brain-language fusion as a new tool for probing visually evoked brain responses"
date: 2025-09-09
---

### MindLLM: A Subject-Agnostic and Versatile Model for fMRI-to-Text Decoding

Summary: In this seminar, we will explore a novel fMRI-to-text decoding framework named MindLLM. It combines a neuroscience-informed, subject-agnostic fMRI encoder with an off-the-shelf large language model to translate brain activity into coherent text. It introduces Brain Instruction Tuning (BIT), which enriches the model’s capacity to extract and represent diverse semantic information from fMRI signals, enabling versatile decoding across different tasks and subjects. We will discuss how to implement these techniques in our study.

[Qiu, Weikang, et al. "MindLLM: A Subject-Agnostic and Versatile Model for fMRI-to-Text Decoding." arXiv preprint arXiv:2502.15786 (2025).](https://arxiv.org/abs/2502.15786)

### Generative language reconstruction from brain recordings

Summary: Using non-invasive fMRI, the authors map brain-decoded semantic representations into a large language model so it can autoregressively generate text aligned with the perceived stimulus—achieving direct brain-to-language generation without pre-constructed candidates and better alignment than selection-based baselines.

[Ye, Ziyi, et al. "Generative language reconstruction from brain recordings." Communications Biology 8.1 (2025): 346.](https://www.nature.com/articles/s42003-025-07731-7)

### CorText-AMA: brain-language fusion as a new tool for probing visually evoked brain responses

Summary: CorText-AMA introduces an end-to-end brain–language framework that fuses fMRI signals with a large language model to caption and answer questions about natural scenes via an interactive chat interface, enabling targeted probing of what visual-cortex activity encodes and outperforming control models using functional alignment.

[Bosch, Victoria, et al. "CorText-AMA: brain-language fusion as a new tool for probing visually evoked brain responses."](https://init-self.com/assets/pdf/CorText_QA_CCN2025.pdf)
