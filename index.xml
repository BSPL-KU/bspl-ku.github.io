<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Brain Signal Processing Lab</title><link>https://bspl.korea.ac.kr/</link><atom:link href="https://bspl.korea.ac.kr/index.xml" rel="self" type="application/rss+xml"/><description>Brain Signal Processing Lab</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2021 BSPL</copyright><lastBuildDate>Fri, 30 Jul 2021 00:00:00 +0000</lastBuildDate><image><url>https://bspl.korea.ac.kr/media/icon_hu746e86b219933ead05b970d8e60fbf48_161589_512x512_fill_lanczos_center_3.png</url><title>Brain Signal Processing Lab</title><link>https://bspl.korea.ac.kr/</link></image><item><title>Dr. Kim, Hyun-Chul is a Professor at Kyungpook National University!</title><link>https://bspl.korea.ac.kr/news/2021_07_30_drkimhc_facultyposition/</link><pubDate>Fri, 30 Jul 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/news/2021_07_30_drkimhc_facultyposition/</guid><description>&lt;table>
&lt;tr>
&lt;td>
&lt;div style='width:400px'>
&lt;center> &lt;img src='https://bspl.korea.ac.kr/image/bspl/DrKimHC_circle.png' width=400> &lt;/center>
&lt;/td>
&lt;td>
&lt;div style='width:2000'>
&lt;p style='font-size: 20px'> Our former graduate student (currently, post-doc at Harvard Medical School) Dr. Hyun-Chul Kim will move to Kyungpook National University from September/2021 to become an Assistant Professor at the Department of Artificial Intelligence! &lt;/p>
&lt;p style='font-size: 20px'> Many congrats Dr. Kim for your achievement! &lt;/p>
&lt;p style='font-size: 20px'> All the best in your new position and keep up the great work! &lt;/p> &lt;/div>
&lt;/td>
&lt;/tr>
&lt;/table></description></item><item><title>[Article] natomical and functional properties of the foot and leg representation in areas 3b, 1 and 2 of primary somatosensory cortex in humans: A 7T fMRI study</title><link>https://bspl.korea.ac.kr/interesting_works/2021_07_28_akselrod_etal_neuroimage_2017/</link><pubDate>Wed, 28 Jul 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/interesting_works/2021_07_28_akselrod_etal_neuroimage_2017/</guid><description>&lt;p>Summary: In this paper, lower limb somatotopy mapping was investigated whether each mapped representation also responded to the stimulation of other body parts
(i.e., response selectivity) and conducted dissimilarity analysis relating these anatomical and functional properties of S1 to the physical structure of
the lower limbs. They found only minor differences between the properties of the three BAs of somasensory areas (i.e., BA 3,1,2), suggesting that S1 maps for the lower limbs differ from those described for the hand. Furthermore, this paper suggested a possible homology between the first digit of upper and lower extremity in humans, and report different patterns of selectivity in the foot representations (i.e. lower selectivity) compared to the other leg representations (i.e. greater selectivity)&lt;/p>
&lt;!-- ![Image](https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41593-020-0641-7/MediaObjects/41593_2020_641_Fig2_HTML.png#50) -->
&lt;p>&lt;a href="https://www.sciencedirect.com/science/article/pii/S1053811917304901" target="_blank" rel="noopener">Akselrod, Michel, et al. (2017) Anatomical and functional properties of the foot and leg representation in areas 3b, 1 and 2 of primary somatosensory cortex in humans: A 7T fMRI study. Neuroimage 159, 473-487.
&lt;/a> &lt;br/>&lt;/p></description></item><item><title>[Invited seminar] Basics of Imaging-Genetics Analysis (주윤정 교수님, 고려대학교)</title><link>https://bspl.korea.ac.kr/news/2021_07_19_invited_seminar/</link><pubDate>Mon, 19 Jul 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/news/2021_07_19_invited_seminar/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//sites.google.com/site/bsplkoreauniversity/_/rsrc/1626686303538/documents/gallery/invitedseminarbasicsofimaging-geneticsanalysisjuyunjeonggyosunimgolyeodaehaggyo/%EC%9D%B4%EB%AF%B8%EC%A7%80%201.png#50" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>[2021.06.23] Jinwoo's Birthday</title><link>https://bspl.korea.ac.kr/news/2021_06_28_birthday/</link><pubDate>Mon, 28 Jun 2021 13:40:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/news/2021_06_28_birthday/</guid><description>&lt;div class="row image-space ">
&lt;img src="//bspl.korea.ac.kr/Board/Gallery/IMG-1578.JPG#25" alt="Image">
&lt;img src="//bspl.korea.ac.kr/Board/Gallery/IMG-1577.JPG#25" alt="Image">
&lt;/div>
&lt;p>Happy Birthday!&lt;/p></description></item><item><title>[2021. 06. 22] OHBM 2021</title><link>https://bspl.korea.ac.kr/news/2021_06_28_ohbm/</link><pubDate>Mon, 28 Jun 2021 13:36:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/news/2021_06_28_ohbm/</guid><description>&lt;div class="row image-space ">
&lt;img src="//bspl.korea.ac.kr/Board/Gallery/IMG-1574.JPG#25" alt="Image">
&lt;img src="//bspl.korea.ac.kr/Board/Gallery/IMG-1573.JPG#25" alt="Image">
&lt;img src="//bspl.korea.ac.kr/Board/Gallery/IMG-1575.JPG#25" alt="Image">
&lt;/div>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/Board/Gallery/IMG-1576.PNG#50" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>[2021.06.10] Minseok's Birthday</title><link>https://bspl.korea.ac.kr/news/2021_06_28_birthday2/</link><pubDate>Mon, 28 Jun 2021 10:04:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/news/2021_06_28_birthday2/</guid><description>&lt;div class="row image-space ">
&lt;img src="//bspl.korea.ac.kr/Board/Gallery/IMG-1340.jpg#25" alt="Image">
&lt;img src="//bspl.korea.ac.kr/Board/Gallery/IMG-1343.jpg#25" alt="Image">
&lt;/div>
&lt;p>Happy Birthday!&lt;/p></description></item><item><title>Deep Neural Networks Reveal Category-Selectivity between Digit and Object</title><link>https://bspl.korea.ac.kr/publications/international_conferences/2021_06_26_ohbm/</link><pubDate>Sat, 26 Jun 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/international_conferences/2021_06_26_ohbm/</guid><description>&lt;p>MY Jung, Niv Lustig, JH Lee.&lt;/p>
&lt;div class="bright-green ">
OHBM 2021/Jun, Virtual
&lt;/div></description></item><item><title>Brain Information Processing in Different Modalities: from Activation to Connectivity</title><link>https://bspl.korea.ac.kr/publications/international_conferences/2021_06_25_ohbm4/</link><pubDate>Fri, 25 Jun 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/international_conferences/2021_06_25_ohbm4/</guid><description>&lt;p>Lee J, Kim HC, Kim JS, Jo SM, Jung MY, Lee JH.&lt;/p>
&lt;div class="bright-green ">
OHBM 2021/Jun, Virtual
&lt;/div></description></item><item><title>Predicting General Psychopathology Factor from Functional Connectivity via Site-Adaptation Neural Networks</title><link>https://bspl.korea.ac.kr/publications/international_conferences/2021_06_25_ohbm3/</link><pubDate>Fri, 25 Jun 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/international_conferences/2021_06_25_ohbm3/</guid><description>&lt;p>Jinwoo Hong, Lee JH.&lt;/p>
&lt;div class="bright-green ">
OHBM 2021/Jun, Virtual
&lt;/div></description></item><item><title>Simultaneously acquired EEG and fMRI BOLD signals reflecting Spatiotemporal features of Mindfulness</title><link>https://bspl.korea.ac.kr/publications/international_conferences/2021_06_25_ohbm2/</link><pubDate>Fri, 25 Jun 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/international_conferences/2021_06_25_ohbm2/</guid><description>&lt;p>Kang JE, Lee CH, Kim YJ, Lee JH.&lt;/p>
&lt;div class="bright-green ">
OHBM 2021/Jun, Virtual
&lt;/div></description></item><item><title>Spatial localization of lower limb movement on whole brain using 3D- pose estimation : an fMRI study</title><link>https://bspl.korea.ac.kr/publications/international_conferences/2021_06_25_ohbm5/</link><pubDate>Fri, 25 Jun 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/international_conferences/2021_06_25_ohbm5/</guid><description>&lt;p>Minji Park, Sungman Jo, Dong-Youl Kim, MinSeok Choi, Soohyun Jeon, Inchan Youn, Song Joo Lee, Jong-Hwan Lee&lt;/p>
&lt;div class="bright-green ">
OHBM 2021/Jun, Virtual
&lt;/div></description></item><item><title>Spatio-Temporal Neural Pathways in Emotion Recognition Modulated by Meditation : EEG-fMRI Study</title><link>https://bspl.korea.ac.kr/publications/international_conferences/2021_06_25_ohbm/</link><pubDate>Fri, 25 Jun 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/international_conferences/2021_06_25_ohbm/</guid><description>&lt;p>Lee CH, Kang JE, Kim YJ, Lee JH.&lt;/p>
&lt;div class="bright-green ">
OHBM 2021/Jun, Virtual
&lt;/div></description></item><item><title>Post-doctoral fellowship for Dr. Kim</title><link>https://bspl.korea.ac.kr/news/2021_06_24_drkimdy_postdoc_fellowship/</link><pubDate>Thu, 24 Jun 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/news/2021_06_24_drkimdy_postdoc_fellowship/</guid><description>&lt;table>
&lt;tr>
&lt;td>
&lt;div style='width:400px'>
&lt;center> &lt;img src='https://bspl.korea.ac.kr/image/bspl/DrKimDY_circle.png' width=400> &lt;/center>
&lt;/td>
&lt;td>
&lt;div style='width:2000'>
&lt;p style='font-size: 20px'> Our former graduate student (currently, Research Professor at Korea University) Dr. Kim, Dong-Youl recently awarded a post-doctoral fellowship from Virginia Tech to start the position this fall! &lt;/p>
&lt;p style='font-size: 20px'> Dr. Kim will be working with world-renowned researchers (Profs. Pearl Chiu, Brooks King-Casas, and Stephen LaConte) to further extend his expertise on cognitive/social neuroscience using neuroimaging and real-time fMRI based neurofeedback. &lt;/p>
&lt;p style='font-size: 20px'> Many congrats on his next career move and all the best in the new environment! &lt;/p> &lt;/div>
&lt;/td>
&lt;/tr>
&lt;/table></description></item><item><title>New research grant on Imaging-Genetics</title><link>https://bspl.korea.ac.kr/news/2021_06_21_ig_grant/</link><pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/news/2021_06_21_ig_grant/</guid><description>&lt;p>We have recently awarded a new three-year research grant from the National Research Foundation of Korea as the leading team of the second group of the teams in the BIG-BRAIN project!&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/Board/Lab_News/BigBrain_kickoff_photo_21jun21.png#50" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>[2021.05.18] Professor's Birthday</title><link>https://bspl.korea.ac.kr/news/2021_06_02_birthday/</link><pubDate>Wed, 02 Jun 2021 10:46:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/news/2021_06_02_birthday/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/Board/Gallery/IMG-1284.jpg#25" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/Board/Gallery/IMG-1287.JPG#50" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>[JHL] Thank you so much!! :)&lt;/p></description></item><item><title>[2021.5.14] Teacher's Day</title><link>https://bspl.korea.ac.kr/news/2021_06_02_teachers_day/</link><pubDate>Wed, 02 Jun 2021 10:21:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/news/2021_06_02_teachers_day/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/Board/Gallery/20210514/20210514_teachersday/DSC_0063.JPG#50" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Thank you, Professor!&lt;/p></description></item><item><title>Predictors of Real-Time fMRI Neurofeedback Performance and Improvement – a Machine Learning Mega-Analysis</title><link>https://bspl.korea.ac.kr/publications/articles/2021_05_21_neuroimage/</link><pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/articles/2021_05_21_neuroimage/</guid><description>&lt;p>Amelie Haugg, Fabian M. Renz; Andrew A. Nicholson; Cindy Lor; Sebastian J. Götzendorfer; Ronald Sladky; Stavros Skouras; Amalia McDonald; Cameron Craddock; Lydia Hellrung; Matthias Kirschner; Marcus Herdener; Yury Koush; Marina Papoutsi; Jackob Keynan; Talma Hendler; Kathrin Cohen Kadosh; Catharina Zich; Simon H. Kohl; Manfred Hallschmid; Jeff MacInnes; R. Alison Adcock; Kathryn Dickerson; Nan-Kuei Chen; Kymberly Young; Jerzy Bodurka; Michael Marxen; Shuxia Yao; Benjamin Becker; Tibor Auer; Renate Schweizer; Gustavo Pamplona; Ruth A. Lanius; Kirsten Emmert; Sven Haller; Dimitri Van De Ville; &lt;strong>Dong-Youl Kim&lt;/strong>; &lt;strong>Jong-Hwan Lee&lt;/strong>; Theo Marins; Megumi Fukuda; Bettina Sorger; Tabea Kamp; Sook-Lei Liew; Ralf Veit; Maartje Spetter; Nikolaus Weiskopf; Frank Scharnowski; David Steyrl&lt;/p>
&lt;div class="bright-green ">
NeuroImage, 237, 15 August 2021, 118207. doi: 10.1016/j.neuroimage.2021.118207
&lt;/div>
&lt;p>[&lt;a href="https://pubmed.ncbi.nlm.nih.gov/34048901/" target="_blank" rel="noopener">PubMed&lt;/a> /
&lt;a href="https://scholar.google.com/scholar?hl=en&amp;amp;as_sdt=0%2C5&amp;amp;q=Predictors&amp;#43;of&amp;#43;real-time&amp;#43;fMRI&amp;#43;neurofeedback&amp;#43;performance&amp;#43;and&amp;#43;improvement&amp;#43;%E2%80%93&amp;#43;A&amp;#43;machine&amp;#43;learning&amp;#43;mega-analysis&amp;amp;btnG=" target="_blank" rel="noopener">Google Scholar&lt;/a> /
&lt;a href="https://www.sciencedirect.com/science/article/pii/S1053811921004845" target="_blank" rel="noopener">Journal Home&lt;/a>]&lt;/p></description></item><item><title>Pathway That Transitions Brain From Plasticity to Stability Discovered</title><link>https://bspl.korea.ac.kr/interesting_works/2021_04_10_nature/</link><pubDate>Sat, 10 Apr 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/interesting_works/2021_04_10_nature/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://sites.google.com/site/bsplkoreauniversity/_/rsrc/1625602885607/general/pathwaythattransitionsbrainfromplasticitytostabilitydiscovered/Screenshot%20from%202021-04-10%2002-15-44.png" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Astrocytes help transition the brain from a highly plastic state to one that is more stable.&lt;/p>
&lt;p>&lt;a href="https://www.nature.com/articles/s41586-021-03441-2" target="_blank" rel="noopener">“Astrocytes close a motor circuit critical period” by Sarah D. Ackerman, Nelson A. Perez-Catalan, Marc R. Freeman &amp;amp; Chris Q. Doe. Nature&lt;/a>&lt;/p></description></item><item><title>How sex differences play a role in neurological diseases</title><link>https://bspl.korea.ac.kr/interesting_works/2021_03_26_apl/</link><pubDate>Fri, 26 Mar 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/interesting_works/2021_03_26_apl/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://earimediaprodweb.azurewebsites.net/Api/v1/Multimedia/0df93124-2348-4d0e-ab9b-3c57f29e3422/Rendition/low-res/Content/Public" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Separating vascular cell data based on sex helps researchers make new discoveries about why males and females are affected by neurodegenerative* diseases differently.
Findings point to differences in the blood-brain barrier between males and females.&lt;/p>
&lt;p>*neurodegenerative : the progressive loss of structure or function of neurons, including their death&lt;/p>
&lt;p>&lt;a href="https://aip.scitation.org/doi/10.1063/5.0035610" target="_blank" rel="noopener">Weber, Callie M., and Alisa Morss Clyne. &amp;ldquo;Sex differences in the blood–brain barrier and neurodegenerative diseases.&amp;rdquo; APL Bioengineering 5.1 (2021): 011509.&lt;/a>&lt;/p></description></item><item><title>Study links genes with function across the human brain</title><link>https://bspl.korea.ac.kr/interesting_works/2021_03_26_nature2/</link><pubDate>Fri, 26 Mar 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/interesting_works/2021_03_26_nature2/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://www.mcgill.ca/neuro/files/neuro/channels/image/press_release.png" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>A new study, that utilized machine learning tools, provides a new map that links genetic signatures to functions across the human brain!&lt;/p>
&lt;p>Interestingly, they found a clear genetic signal that separated cognitive processes, like attention, from more affective processes, like fear.
This separation can be traced to gene expression in specific cell types and molecular pathways, offering key insights for future research into psychiatric disorders.&lt;/p>
&lt;p>Cognition, for example, was linked more to the gene signatures of inhibitory or excitatory neurons.
Affective processes, however, were linked to support cells such as microglia and astrocytes, supporting a theory that inflammation of these cells is a risk factor in mental illness.
The genetic signature related to affect was centred on a brain region called the anterior cingulate cortex, which has been shown to be vulnerable in mental illness.&lt;/p>
&lt;p>See the &lt;a href="https://www.nature.com/articles/s41562-021-01082-z" target="_blank" rel="noopener">https://www.nature.com/articles/s41562-021-01082-z&lt;/a> &lt;br />
Published in the journal Nature Human Behaviour on March 25, 2021 &lt;br />
(this study draws a direct link between gene expression and higher brain function, by mapping gene signatures to functional processes across the human brain.)&lt;/p></description></item><item><title>[2021.3.17] Celebration of Dr. Dong-Youl Kim Ph.D Degree</title><link>https://bspl.korea.ac.kr/news/2021_03_17_phd_degree/</link><pubDate>Wed, 17 Mar 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/news/2021_03_17_phd_degree/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/Board/Gallery/DrKim_2021.png" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>The evolution of overconfidence</title><link>https://bspl.korea.ac.kr/interesting_works/2021_03_15_nature/</link><pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/interesting_works/2021_03_15_nature/</guid><description>&lt;p>&lt;a href="https://www.nature.com/articles/nature10384?message-global=remove&amp;amp;page=1" target="_blank" rel="noopener">Johnson, D. D., &amp;amp; Fowler, J. H. (2011). The evolution of overconfidence. Nature, 477(7364), 317-320.&lt;/a>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://sites.google.com/site/bsplkoreauniversity/_/rsrc/1625602885607/general/theevolutionofoverconfidence/20210315_16%3A54%3A49.png?height=396&amp;amp;width=400" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Interestingly, the authors found that overconfidence maximizes individual fitness and populations tend to become overconfident.&lt;/p></description></item><item><title>[Invited seminar] Independent Component Analysis and Independent Vector Analysis (박형민 교수님, 서강대학교)</title><link>https://bspl.korea.ac.kr/news/2021_02_27_invited_seminar/</link><pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/news/2021_02_27_invited_seminar/</guid><description>&lt;div class="row image-space ">
&lt;img src="//bspl.korea.ac.kr/Board/Members_Only/Research_Materials/Education/invited_seminar/ProfParkHM_SU/BSPL_seminar_ProfParkHM_21feb26_1.png#25" alt="Image">
&lt;img src="//bspl.korea.ac.kr/Board/Members_Only/Research_Materials/Education/invited_seminar/ProfParkHM_SU/BSPL_seminar_ProfParkHM_21feb26_2.png#25" alt="Image">
&lt;/div>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://bspl.korea.ac.kr/Board/Members_Only/Research_Materials/Education/invited_seminar/ProfParkHM_SU/BSPL_seminar_ProfParkHM_21feb26.png#75" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>[Article] How Our Visual System Avoids Overloading</title><link>https://bspl.korea.ac.kr/interesting_works/2021_02_23_scientific_reports/</link><pubDate>Tue, 23 Feb 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/interesting_works/2021_02_23_scientific_reports/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://neurosciencenews.com/files/2021/02/visual-system-overload-neuroscience.jpg#25" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>The human brain has limited capacity in terms of the data it is able to process and save in its memory. Researchers sought to answer the following question: is the visual system capable of automatic object categorization (i.e., without attention)? To this end, they tested whether the rapid categorical parsing is automatic or requires attention. They found that spatially intermixed objects are parsed into distinct categories automatically.&lt;/p>
&lt;p>How Our Visual System Avoids Overloading&lt;/p>
&lt;p>&lt;a href="https://www.nature.com/articles/s41598-020-79828-4" target="_blank" rel="noopener">“Spatially intermixed objects of different categories are parsed automatically” by Vladislav A. Khvostov, Anton O. Lukashevich &amp;amp; Igor S. Utochkin. Scientific Reports&lt;/a>&lt;/p></description></item><item><title>Cigarette craving modulation is more feasible than resistance modulation for heavy cigarette smokers: Empirical evidence from functional MRI data</title><link>https://bspl.korea.ac.kr/publications/articles/2021_02_16_neuroreport/</link><pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/articles/2021_02_16_neuroreport/</guid><description>&lt;p>&lt;strong>DY Kim&lt;/strong>, M Tegethoff, G Meinlschmidt, SS Yoo, &lt;strong>JH Lee&lt;/strong>&lt;/p>
&lt;div class="bright-green ">
Neuroreport, 32 (9), June 9, 2021 doi: 10.1097/WNR.0000000000001653
&lt;/div>
&lt;p>[&lt;a href="https://pubmed.ncbi.nlm.nih.gov/33901056/" target="_blank" rel="noopener">PubMed&lt;/a> /
&lt;a href="https://scholar.google.com/scholar?hl=ko&amp;amp;as_sdt=0%2C5&amp;amp;authuser=1&amp;amp;q=Cigarette&amp;#43;craving&amp;#43;modulation&amp;#43;is&amp;#43;more&amp;#43;feasible&amp;#43;than&amp;#43;resistance&amp;#43;modulation&amp;#43;for&amp;#43;heavy&amp;#43;cigarette&amp;#43;smokers%3A&amp;#43;Empirical&amp;#43;evidence&amp;#43;from&amp;#43;functional&amp;#43;MRI&amp;#43;data&amp;amp;btnG=" target="_blank" rel="noopener">Google Scholar&lt;/a> /
&lt;a href="https://journals.lww.com/neuroreport/Abstract/9000/Cigarette_craving_modulation_is_more_feasible_than.97829.aspx" target="_blank" rel="noopener">Journal Home&lt;/a>]&lt;/p></description></item><item><title>[Article] Is What I See, What I Imagine? The Neural Overlap Between Vision and Imagination</title><link>https://bspl.korea.ac.kr/interesting_works/2020_11_02_current_biology/</link><pubDate>Mon, 02 Nov 2020 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/interesting_works/2020_11_02_current_biology/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://ars.els-cdn.com/content/image/1-s2.0-S0960982220304942-gr3.jpg#50" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Using generative networks and functional magnetic resonance imaging (fMRI), researchers found that brain uses similar visual areas for mental imagery and vision, but it uses low-level visual areas less precisely with mental imagery than with vision. Namely, there are distinct codes for seen and mental images in the brain which can be captured by generative networks.&lt;/p>
&lt;p>&lt;a href="https://neurosciencenews.com/vision-imagination-16633/" target="_blank" rel="noopener">Is What I See, What I Imagine? The Neural Overlap Between Vision and Imagination&lt;/a> &lt;br />
&lt;a href="https://www.sciencedirect.com/science/article/pii/S0960982220304942?via%3Dihub" target="_blank" rel="noopener">Breedlove, J. L., St-Yves, G., Olman, C. A., &amp;amp; Naselaris, T. (2020). Generative Feedback Explains Distinct Brain Activity Codes for Seen and Mental Images. Current Biology.&lt;/a>&lt;/p></description></item><item><title>[Article] Meditation for mind-control</title><link>https://bspl.korea.ac.kr/interesting_works/2020_10_05_cerebral_cortex/</link><pubDate>Mon, 05 Oct 2020 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/interesting_works/2020_10_05_cerebral_cortex/</guid><description>&lt;p>
&lt;figure id="figure-alpha-power-contrast-between-motor-imagery-and-rest-is-widespread-a-the-fisher-score-was-used-to-plot-the-difference-between-the-distributions-of-alpha-power-during-motor-imagery-versus-rest-at-each-electrode-throughout-training-x-axissession-number-during-the-ud-task-the-control-group-top-row-displayed-the-expected-pattern-in-that-the-difference-between-motor-imagery-and-rest-is-determined-by-the-presence-or-absence-of-activity-over-the-motor-cortex-however-the-mbsr-group-produced-an-entirely-different-pattern-of-contrast-that-evolves-throughout-training-brighter-colors-represent-greater-differences-in-alpha-power-between-trial-types-b-comparing-the-change-in-fisher-score-across-the-cortex-during-ud-control-revealed-the-mbsr-group-learned-to-generate-greater-alpha-power-contrast-between-motor-imagery-and-rest-than-controls-across-a-wide-range-of-electrodes-cbpt-p-001-c-source-imaging-of-the-group-difference-in-fisher-score-change-during-the-ud-task-again-confirms-the-differences-in-learned-alpha-power-modulation-are-widespread-cbpt-p">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://neurosciencenews.com/files/2020/09/meditation-mind-control-neuroscineews.jpg" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Alpha power contrast between motor imagery and rest is widespread. (A) The Fisher score was used to plot the difference between the distributions of alpha power during motor imagery versus rest at each electrode throughout training (x-axis = session number). During the UD task, the control group (top row) displayed the expected pattern in that the difference between motor imagery and rest is determined by the presence or absence of activity over the motor cortex. However, the MBSR group produced an entirely different pattern of contrast that evolves throughout training. Brighter colors represent greater differences in alpha power between trial types. (B) Comparing the change in Fisher score across the cortex during UD control revealed the MBSR group learned to generate greater alpha power contrast between motor imagery and rest than controls across a wide range of electrodes (CBPT, P = 0.01). (C) Source imaging of the group difference in Fisher score change during the UD task again confirms the differences in learned alpha power modulation are widespread (CBPT, P &amp;lt; 0.001).
&lt;/figcaption>&lt;/figure>
&lt;/p>
&lt;p>The team found that those with training in mindfulness-based attention and training (MBAT) were more successful in controlling the BCI, both initially and over time. Interestingly, the researchers found that differences in brain activity between the two sample groups corresponded directly with their success. The meditation group showed significantly enhanced capability of modulating their alpha rhythm, the activity pattern monitored by the BCI system to mentally control the movement of a computer cursor.&lt;/p>
&lt;p>His findings are very important for the process of BCI training and the overall feasibility of non-invasive BCI control via EEG. This work shows that just a short period of MBAT training can significantly improve a subject’s skill with a BCI. This suggests that education in MBAT could provide a significant addition to BCI training.&lt;/p>
&lt;p>&lt;a href="https://neurosciencenews.com/meditation-mind-control-17071/" target="_blank" rel="noopener">https://neurosciencenews.com/meditation-mind-control-17071/&lt;/a> &lt;br />
&lt;a href="https://academic.oup.com/cercor/advance-article/doi/10.1093/cercor/bhaa234/5910197" target="_blank" rel="noopener">Mindfulness Improves Brain–Computer Interface Performance by Increasing Control Over Neural Activity in the Alpha Band James R Stieger, Stephen Engel, Haiteng Jiang, Christopher C Cline, Mary Jo Kreitzer, Bin He&lt;/a>&lt;/p></description></item><item><title>Deep learning methods and applications in neuroimaging</title><link>https://bspl.korea.ac.kr/publications/articles/2020_09_24_jneurosci_methods/</link><pubDate>Thu, 24 Sep 2020 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/articles/2020_09_24_jneurosci_methods/</guid><description>&lt;p>Jing Sui, MingXia Liu, &lt;strong>Jong-Hwan Lee&lt;/strong>, Jun Zhang, Vince Calhoun&lt;/p>
&lt;div class="bright-green ">
J Neurosci Methods. 2020 Jun 1;339:108718. doi: 10.1016/j.jneumeth.2020.108718. Epub 2020 Apr 6.
&lt;/div>
&lt;p>[&lt;a href="https://pubmed.ncbi.nlm.nih.gov/32272117/" target="_blank" rel="noopener">PubMed&lt;/a> /
&lt;a href="https://scholar.google.com/scholar?hl=en&amp;amp;as_sdt=0%2C5&amp;amp;q=Deep&amp;#43;learning&amp;#43;methods&amp;#43;and&amp;#43;applications&amp;#43;in&amp;#43;neuroimaging&amp;amp;btnG=" target="_blank" rel="noopener">Google Scholar&lt;/a> /
&lt;a href="https://www.sciencedirect.com/science/article/pii/S0165027020301412?via%3Dihub" target="_blank" rel="noopener">Journal Home&lt;/a>]&lt;/p></description></item><item><title>[Article] Researchers Uncover Network Mechanism Underlying Rumination</title><link>https://bspl.korea.ac.kr/interesting_works/2020_09_01_neuroimage/</link><pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/interesting_works/2020_09_01_neuroimage/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://sites.google.com/site/bsplkoreauniversity/_/rsrc/1625602885288/general/articleresearchersuncovernetworkmechanismunderlyingrumination/%EC%A0%9C%EB%AA%A9%20%EC%97%86%EB%8A%94%20%ED%94%84%EB%A0%88%EC%A0%A0%ED%85%8C%EC%9D%B4%EC%85%98%281%29.png" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Researchers have uncovered the neural mechanism underlying rumination. The study reports when rumination occurs, coupling between the core and medial temporal lobe subsystems of the default mode network becomes elevated while coupling between the core and dorsomedial prefrontal cortex decreases. According to this study, they computed the Pearson’s correlation during the activity among different brain regions. Results revealed that couplings between the core and the medial temporal lobe (MTL) subsystems of the default mode network (DMN) were elevated while the other couplings were decreased.&lt;/p>
&lt;p>&lt;a href="https://neurosciencenews.com/rumination-mechanism-16929/" target="_blank" rel="noopener">News&lt;/a> /
&lt;a href="https://www.sciencedirect.com/science/article/pii/S1053811920306716?via%3Dihub" target="_blank" rel="noopener">Article&lt;/a>&lt;/p></description></item><item><title>fMRI volume classification using a 3D convolutional neural network robust to shifted and scaled neuronal activations</title><link>https://bspl.korea.ac.kr/publications/articles/2020_08_10_neuroimage/</link><pubDate>Mon, 10 Aug 2020 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/articles/2020_08_10_neuroimage/</guid><description>&lt;p>&lt;strong>Vu H&lt;/strong>, &lt;strong>Kim HC&lt;/strong>, &lt;strong>Jung M&lt;/strong>, &lt;strong>Lee JH&lt;/strong>&lt;/p>
&lt;div class="bright-green ">
NeuroImage, Vol. 223, Dec. 2020, doi: 10.1016/j.neuroimage.2020.117328
&lt;/div>
&lt;p>[&lt;a href="https://pubmed.ncbi.nlm.nih.gov/32896633/" target="_blank" rel="noopener">PubMed&lt;/a> /
&lt;a href="https://scholar.google.com/scholar?hl=ko&amp;amp;as_sdt=0%2C5&amp;amp;q=fMRI&amp;#43;volume&amp;#43;classification&amp;#43;using&amp;#43;a&amp;#43;3D&amp;#43;convolutional&amp;#43;neural&amp;#43;network&amp;#43;robust&amp;#43;to&amp;#43;shifted&amp;#43;and&amp;#43;scaled&amp;#43;neuronal&amp;#43;activations&amp;amp;btnG=" target="_blank" rel="noopener">Google Scholar&lt;/a> /
&lt;a href="https://www.sciencedirect.com/science/article/pii/S1053811920308144" target="_blank" rel="noopener">Journal Home&lt;/a>]&lt;/p></description></item><item><title>[Article] MRI scans of the brains of 130 mammals, including humans, indicate equal connectivity</title><link>https://bspl.korea.ac.kr/interesting_works/2020_07_22_natneuro/</link><pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/interesting_works/2020_07_22_natneuro/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41593-020-0641-7/MediaObjects/41593_2020_641_Fig2_HTML.png#50" alt="Image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Researchers conducted a first-of-its-kind study designed to investigate brain connectivity in 130 mammalian species. The intriguing results, contradicting widespread conjectures, revealed that brain connectivity levels are equal in all mammals, including humans.&lt;/p>
&lt;p>Their study revealed a universal law: Conservation of Brain Connectivity which denotes that the efficiency of information transfer in the brain&amp;rsquo;s neural network is equal in all mammals, including humans. They also discovered a compensation mechanism which balances the connectivity in every mammalian brain. This mechanism ensures that high connectivity in a specific area of the brain, possibly manifested through some special talent (e.g. sports or music) is always countered by relatively low connectivity in another part of the brain.&lt;/p>
&lt;p>In future projects they will investigate how the brain compensates for the enhanced connectivity associated with specific capabilities and learning processe.&lt;/p>
&lt;p>&lt;a href="https://www.sciencedaily.com/releases/2020/07/200720112216.htm" target="_blank" rel="noopener">https://www.sciencedaily.com/releases/2020/07/200720112216.htm&lt;/a> &lt;br />
&lt;a href="https://www.nature.com/articles/s41593-020-0641-7" target="_blank" rel="noopener">Yaniv Assaf, Arieli Bouznach, Omri Zomet, Assaf Marom, Yossi Yovel. Conservation of brain connectivity and wiring across the mammalian class. Nature Neuroscience, 2020; 23 (7): 805&lt;/a>&lt;/p></description></item><item><title>Investigation of image and sound processing of the human brain using multisensory stimuli</title><link>https://bspl.korea.ac.kr/publications/international_conferences/2020_07_21_ohbm/</link><pubDate>Tue, 21 Jul 2020 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/international_conferences/2020_07_21_ohbm/</guid><description>&lt;p>MY Jung, Lee WW, Niv Lustig, Choi MS, Lee JH.&lt;/p>
&lt;div class="bright-green ">
OHBM 2020/Jun, Virtual
&lt;/div></description></item><item><title>Investigation of Multimodality from Unimodal Classification Using Deep Neural Network: Image &amp; Text</title><link>https://bspl.korea.ac.kr/publications/international_conferences/2020_07_21_ohbm3/</link><pubDate>Tue, 21 Jul 2020 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/international_conferences/2020_07_21_ohbm3/</guid><description>&lt;p>Lee J, Lee CH, Kim HC, Jo SM, Jung MY, Lee JH.&lt;/p>
&lt;div class="bright-green ">
OHBM 2020/Jun, Virtual
&lt;/div></description></item><item><title>Understanding Human Reasoning from the Text of bAbI Dataset</title><link>https://bspl.korea.ac.kr/publications/international_conferences/2020_07_21_ohbm2/</link><pubDate>Tue, 21 Jul 2020 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/international_conferences/2020_07_21_ohbm2/</guid><description>&lt;p>Lee J, Choi MS, Kim JS, Kim HC, Jo SM, Lee JH.&lt;/p>
&lt;div class="bright-green ">
OHBM 2020/Jun, Virtual
&lt;/div></description></item><item><title>Can we predict real-time fMRI neurofeedback learning success from pre-training brain activity?</title><link>https://bspl.korea.ac.kr/publications/articles/2020_06_23_hbm/</link><pubDate>Tue, 23 Jun 2020 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/articles/2020_06_23_hbm/</guid><description>&lt;p>Haugg A., Sladky R., Skouras S., McDonald A., Craddock C., Kirschner M., Herdener M., Koush Y., Papoutsi M., Keynan J.N., Hendler T., Cohen Kadosh K., Zich C., MacInnes J., Adcock A., Dickerson K., Chen N-K., Young K., Bodurka J., Yao S., Becker B., Auer T., Schweizer R., Pamplona G., Emmert K., Haller S., Van De Ville D., Blefari M.L., &lt;strong>Kim D-Y.&lt;/strong>, &lt;strong>Lee J-H.&lt;/strong>, Marins T.F., Megumi F., Sorger B., Kamp T., Liew S-L., Veit R., Spetter M., Weiskopf N., Scharnowski F&lt;/p>
&lt;div class="bright-green ">
Human Brain Mapping, 30 July 2020, doi: 10.1002/hbm.25089
&lt;/div>
&lt;p>[&lt;a href="https://pubmed.ncbi.nlm.nih.gov/32729652/" target="_blank" rel="noopener">PubMed&lt;/a> /
&lt;a href="https://scholar.google.com/scholar?hl=en&amp;amp;as_sdt=0%2C5&amp;amp;q=Can&amp;#43;we&amp;#43;predict&amp;#43;real-time&amp;#43;fMRI&amp;#43;neurofeedback&amp;#43;learning&amp;#43;success&amp;#43;from&amp;#43;pre-training&amp;#43;brain&amp;#43;activity%3F&amp;amp;btnG=" target="_blank" rel="noopener">Google Scholar&lt;/a> /
&lt;a href="https://onlinelibrary.wiley.com/doi/full/10.1002/hbm.25089" target="_blank" rel="noopener">Journal Home&lt;/a>]&lt;/p></description></item><item><title>Functional magnetic resonance imaging multivoxel pattern analysis reveals neuronal substrates for collaboration and competition with myopic and predictive strategic reasoning</title><link>https://bspl.korea.ac.kr/publications/articles/2020_06_23_human_brain_mapping/</link><pubDate>Tue, 23 Jun 2020 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/articles/2020_06_23_human_brain_mapping/</guid><description>&lt;p>&lt;strong>Kim DY&lt;/strong>, &lt;strong>Jung E&lt;/strong>, Zhang J, Lee SY, &lt;strong>Lee JH&lt;/strong>&lt;/p>
&lt;div class="bright-green ">
Human Brain Mapping, 41(15), Oct. 2020, doi: 10.1002/hbm.25127
&lt;/div>
&lt;p>[&lt;a href="https://pubmed.ncbi.nlm.nih.gov/32633451/" target="_blank" rel="noopener">PubMed&lt;/a> /
&lt;a href="https://scholar.google.com/scholar?hl=en&amp;amp;as_sdt=0%2C5&amp;amp;q=Functional&amp;#43;magnetic&amp;#43;resonance&amp;#43;imaging&amp;#43;multivoxel&amp;#43;pattern&amp;#43;analysis&amp;#43;reveals&amp;#43;neuronal&amp;#43;substrates&amp;#43;for&amp;#43;collaboration&amp;#43;and&amp;#43;competition&amp;#43;with&amp;#43;myopic&amp;#43;and&amp;#43;predictive&amp;#43;strategic&amp;#43;reasoning&amp;amp;btnG=" target="_blank" rel="noopener">Google Scholar&lt;/a> /
&lt;a href="https://onlinelibrary.wiley.com/doi/10.1002/hbm.25127" target="_blank" rel="noopener">Journal Home&lt;/a>]&lt;/p></description></item><item><title>A naturalistic viewing paradigm using 360° panoramic video clips and real-time field-of-view changes with eye-gaze tracking</title><link>https://bspl.korea.ac.kr/publications/articles/2020_02_06_neuroimage/</link><pubDate>Thu, 06 Feb 2020 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/articles/2020_02_06_neuroimage/</guid><description>&lt;p>&lt;strong>Kim HC&lt;/strong>, &lt;strong>Jin S&lt;/strong>, &lt;strong>Jo S&lt;/strong>, &lt;strong>Lee JH&lt;/strong>&lt;/p>
&lt;div class="bright-green ">
NeuroImage, Vol. 216, 2020 Aug 1;216:116617. doi: 10.1016/j.neuroimage.2020.116617.
&lt;/div>
&lt;p>[&lt;a href="https://pubmed.ncbi.nlm.nih.gov/32057996/" target="_blank" rel="noopener">PubMed&lt;/a> /
&lt;a href="https://scholar.google.com/scholar?hl=en&amp;amp;as_sdt=0%2C5&amp;amp;q=A&amp;#43;naturalistic&amp;#43;viewing&amp;#43;paradigm&amp;#43;using&amp;#43;360%C2%B0&amp;#43;panoramic&amp;#43;video&amp;#43;clips&amp;#43;and&amp;#43;real-time&amp;#43;field-of-view&amp;#43;changes&amp;#43;with&amp;#43;eye-gaze&amp;#43;tracking&amp;amp;btnG=" target="_blank" rel="noopener">Google Scholar&lt;/a> /
&lt;a href="https://www.sciencedirect.com/science/article/pii/S105381192030104X?via%3Dihub" target="_blank" rel="noopener">Journal Home&lt;/a>]&lt;/p></description></item><item><title>Does fMRI neurofeedback in the context of stress influence mood and arousal? A randomised controlled trial with parallel group design?</title><link>https://bspl.korea.ac.kr/publications/articles/2019_11_20_f1000_research/</link><pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/articles/2019_11_20_f1000_research/</guid><description>&lt;p>Angelo Belardi, &lt;strong>Jong-Hwan Lee&lt;/strong>, &lt;strong>Hyun-Chul Kim&lt;/strong>, Esther Stalujanis, &lt;strong>Eun Kyung Jung&lt;/strong>, &lt;strong>Minkyung Oh&lt;/strong>, Seung-Schik Yoo, Jens C. Pruessner, Marion Tegethoff, Gunther Meinlschmidt&lt;/p>
&lt;div class="bright-green ">
F1000 Research, In Press
&lt;/div>
&lt;p>[&lt;a href="https://scholar.google.com/scholar?hl=en&amp;amp;as_sdt=0%2C5&amp;amp;q=Does&amp;#43;fMRI&amp;#43;neurofeedback&amp;#43;in&amp;#43;the&amp;#43;context&amp;#43;of&amp;#43;stress&amp;#43;influence&amp;#43;mood&amp;#43;and&amp;#43;arousal%3F&amp;#43;A&amp;#43;randomised&amp;#43;controlled&amp;#43;trial&amp;#43;with&amp;#43;parallel&amp;#43;group&amp;#43;design&amp;amp;btnG=" target="_blank" rel="noopener">Google Scholar&lt;/a> /
&lt;a href="https://f1000research.com/articles/8-1031" target="_blank" rel="noopener">Journal Home&lt;/a>]&lt;/p></description></item><item><title>Personalized prediction of smartphone-based psychotherapeutic micro-intervention success using machine learning</title><link>https://bspl.korea.ac.kr/publications/articles/2019_11_20_jaffective_disorders/</link><pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/articles/2019_11_20_jaffective_disorders/</guid><description>&lt;p>Gunther Meinlschmidt, Marion Tegethoff, Angelo Belardi, Esther Stalujanis, &lt;strong>Minkyung Oh&lt;/strong>, &lt;strong>Eun Kyung Jung&lt;/strong>, &lt;strong>Hyun-Chul Kim&lt;/strong>, Seung-Schik Yoo, &lt;strong>Jong-Hwan Lee&lt;/strong>&lt;/p>
&lt;div class="bright-green ">
Journal of Affective Disorders, 2020 Mar 1;264:430-437. doi: 10.1016/j.jad.2019.11.071. Epub 2019 Nov 14.
&lt;/div>
&lt;p>[&lt;a href="https://pubmed.ncbi.nlm.nih.gov/31787419/" target="_blank" rel="noopener">PubMed&lt;/a> /
&lt;a href="https://scholar.google.com/scholar?hl=en&amp;amp;as_sdt=0%2C5&amp;amp;q=Personalized&amp;#43;prediction&amp;#43;of&amp;#43;smartphone-based&amp;#43;psychotherapeutic&amp;#43;micro-intervention&amp;#43;success&amp;#43;using&amp;#43;machine&amp;#43;learning&amp;amp;btnG=" target="_blank" rel="noopener">Google Scholar&lt;/a> /
&lt;a href="https://www.sciencedirect.com/science/article/pii/S0165032719312121?casa_token=sH7Zo__FKhUAAAAA:MUEEZ-PN6U8_ON8A_z3XYOiG4JZUuO3gku7Vh6sMREUsbppw1f4J7ehC5NfO584cpydyTGOOm9Hh" target="_blank" rel="noopener">Journal Home&lt;/a>]&lt;/p></description></item><item><title>Real-time fMRI neurofeedback of laterality index from stroke patients: Preliminary study</title><link>https://bspl.korea.ac.kr/publications/international_conferences/2019_11_06_ohbm/</link><pubDate>Wed, 06 Nov 2019 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/international_conferences/2019_11_06_ohbm/</guid><description>&lt;p>Kim DY, Kim YH, Kang DH, Lee JH.&lt;/p>
&lt;div class="bright-green ">
OHBM 2019/Jun, Rome
&lt;/div></description></item><item><title>Laterality index modulation of stroke patients evaluated from functional MRI</title><link>https://bspl.korea.ac.kr/publications/domestic_conferences/2019_10_06_korean_society_of_biomechanics/</link><pubDate>Sun, 06 Oct 2019 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/domestic_conferences/2019_10_06_korean_society_of_biomechanics/</guid><description>&lt;p>Kim DY, Park MJ, Kim YH, Kang KH, Lee JH&lt;/p>
&lt;div class="bright-green ">
Korean Society of Biomechanics, Oct/2019
&lt;/div>
&lt;div class="teal ">
&lt;em>[Best Poster Award]&lt;/em>
&lt;/div></description></item><item><title>Decoding a sentence from functional MRI using deep neural network</title><link>https://bspl.korea.ac.kr/publications/domestic_conferences/2019_02_06_besk3/</link><pubDate>Wed, 06 Feb 2019 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/domestic_conferences/2019_02_06_besk3/</guid><description>&lt;p>Lee JHyeon, Kim HC, Kim JS, Jo SM, Lee JH&lt;/p>
&lt;div class="bright-green ">
Brain and Artificial Intelligence Symposium, Brain Engineering Society of Korea (BESK), Feb/2019
&lt;/div></description></item><item><title>Greedy layer-wise parameter-free weight-sparsity control of DNN for classification of fMRI data</title><link>https://bspl.korea.ac.kr/publications/domestic_conferences/2019_02_06_besk4/</link><pubDate>Wed, 06 Feb 2019 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/domestic_conferences/2019_02_06_besk4/</guid><description>&lt;p>Lustig N, Lee JH&lt;/p>
&lt;div class="bright-green ">
Brain and Artificial Intelligence Symposium, Brain Engineering Society of Korea (BESK), Feb/2019
&lt;/div></description></item><item><title>Modulation of laterality index from real-time functional MRI based neurofeedback training for stroke patients</title><link>https://bspl.korea.ac.kr/publications/domestic_conferences/2019_02_06_besk/</link><pubDate>Wed, 06 Feb 2019 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/domestic_conferences/2019_02_06_besk/</guid><description>&lt;p>Kim DY, Kim YH, Kang KH, Lee JH&lt;/p>
&lt;div class="bright-green ">
Brain and Artificial Intelligence Symposium, Brain Engineering Society of Korea (BESK), Feb/2019
&lt;/div></description></item><item><title>Understanding of multimodal image and natural language processing in human brain using deep neural network and functional MRI</title><link>https://bspl.korea.ac.kr/publications/domestic_conferences/2019_02_06_besk2/</link><pubDate>Wed, 06 Feb 2019 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/domestic_conferences/2019_02_06_besk2/</guid><description>&lt;p>Kim HC, Lee JHyeon, Kim JS, Jo SM, Lee JH&lt;/p>
&lt;div class="bright-green ">
Brain and Artificial Intelligence Symposium, Brain Engineering Society of Korea (BESK), Feb/2019
&lt;/div></description></item><item><title>3D convolutional neural network for feature extraction and classification of fMRI volumes</title><link>https://bspl.korea.ac.kr/publications/domestic_conferences/2018_11_06_khbm/</link><pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/domestic_conferences/2018_11_06_khbm/</guid><description>&lt;p>Vu H, Kim HC, Lee JH&lt;/p>
&lt;div class="bright-green ">
Annual meeting of Organisation for Human Brain Mapping, Korea Chapter, Korean Society for Human Brain Mapping (KHBM), Nov/2018
&lt;/div>
&lt;div class="teal ">
&lt;em>[Best Poster Award]&lt;/em>
&lt;/div></description></item><item><title>DNN with Greedy Layer-Wise Parameter-Free weight sparsity control for fMRI data classification</title><link>https://bspl.korea.ac.kr/publications/domestic_conferences/2018_11_06_khbm2/</link><pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/domestic_conferences/2018_11_06_khbm2/</guid><description>&lt;p>Lustig N, Lee JH&lt;/p>
&lt;div class="bright-green ">
Annual meeting of Organisation for Human Brain Mapping, Korea Chapter, Korean Society for Human Brain Mapping (KHBM), Nov/2018
&lt;/div></description></item><item><title>Individual identification applying deep neural networks to dynamic functional connectivity patterns</title><link>https://bspl.korea.ac.kr/publications/domestic_conferences/2018_11_06_khbm3/</link><pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/domestic_conferences/2018_11_06_khbm3/</guid><description>&lt;p>Lee JHyeon, Kim HC, Lee JH&lt;/p>
&lt;div class="bright-green ">
Annual meeting of Organisation for Human Brain Mapping, Korea Chapter, Korean Society for Human Brain Mapping (KHBM), Nov/2018
&lt;/div>
&lt;div class="teal ">
&lt;em>[Best Poster Award]&lt;/em>
&lt;/div></description></item><item><title>Classification of competitive and collaborative decision-making processes across two reasoning orders: multivoxel pattern analysis of fMRI data</title><link>https://bspl.korea.ac.kr/publications/domestic_conferences/2018_01_06_besk/</link><pubDate>Sat, 06 Jan 2018 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/domestic_conferences/2018_01_06_besk/</guid><description>&lt;p>Kim DY, Jung EK, Zhang J, Lee SY, Lee JH&lt;/p>
&lt;div class="bright-green ">
Brain and Artificial Intelligence Symposium, Brain Engineering Society of Korea (BESK), Jan/2018
&lt;/div></description></item><item><title>Identification of functional connectivity associated with mindfulness based on mediation analysis in real-time fMRI neurofeedback</title><link>https://bspl.korea.ac.kr/publications/domestic_conferences/2018_11_06_besk2/</link><pubDate>Sat, 06 Jan 2018 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/domestic_conferences/2018_11_06_besk2/</guid><description>&lt;p>Kim HC, Tegethoff M, Meinlschmidt G, Stalujanis E, Belardi A, Jo SM, Lee JHyeon, Heo DW, Kim DY, Yoo SS, Lee JH.&lt;/p>
&lt;div class="bright-green ">
Brain and Artificial Intelligence Symposium, Brain Engineering Society of Korea (BESK), Jan/2018
&lt;/div></description></item><item><title>Performance evaluation of nonnegative matrix factorization algorithms to estimate task-related neuronal activities from fMRI data</title><link>https://bspl.korea.ac.kr/publications/articles/2013_04_01_ding_etal_mri_2013/</link><pubDate>Mon, 01 Apr 2013 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/publications/articles/2013_04_01_ding_etal_mri_2013/</guid><description>&lt;p>X Ding, &lt;strong>JH Lee&lt;/strong>, SW Lee&lt;/p>
&lt;div class="bright-green ">
Magnetic Resonance Imaging, Vol. 31 (3), April 2013
&lt;/div>
&lt;p>[&lt;a href="https://pubmed.ncbi.nlm.nih.gov/23200679/" target="_blank" rel="noopener">PubMed&lt;/a> /
&lt;a href="https://scholar.google.com/scholar?hl=en&amp;amp;as_sdt=0%2C5&amp;amp;q=Performance&amp;#43;evaluation&amp;#43;of&amp;#43;nonnegative&amp;#43;matrix&amp;#43;factorization&amp;#43;algorithms&amp;#43;to&amp;#43;estimate&amp;#43;task-related&amp;#43;neuronal&amp;#43;activities&amp;#43;from&amp;#43;fMRI&amp;#43;data&amp;amp;btnG=" target="_blank" rel="noopener">Google Scholar&lt;/a> /
&lt;a href="https://www.sciencedirect.com/science/article/pii/S0730725X12003669" target="_blank" rel="noopener">Journal Home&lt;/a>]&lt;/p></description></item><item><title/><link>https://bspl.korea.ac.kr/admin/config.yml</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/admin/config.yml</guid><description/></item><item><title>Aims</title><link>https://bspl.korea.ac.kr/aims/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/aims/</guid><description>&lt;p>Our goal is to investigate brain functions measured via various neuroimaging modalities including MRI (MRI) and electroencephalography (EEG) employing various signal processing techniques, machine learning, and deep learning approaches. We have done some interesting works including the fMRI data analyses using novel analytical methods such as independent vector analysis (IVA), iterative dual-regression of group independent component analysis (ICA) with a sparse prior to better estimate true neuronal activity, recursive principal component analysis (PCA) to EEG-segments of simultaneous EEG-fMRI data, and deep neural network (DNN) to fMRI data. The developed methods would gainfully be applied to the neuroimaging data including fMRI, simultaneous EEG-fMRI, and real-time fMRI based neurofeedback method.&lt;/p>
&lt;p>Based on the correct understanding of human brain functions, we would like to focus on the basic neuroscientific researches as well as brain engineering applications including the BCI/BMI and ultimately on preclinical applications to develop an option to diagnose and treat the various neuropsychiatric illnesses such as depression, schizophrenia, and substance abuse. We believe that the proper analytical methods to exploit the hidden information of the neuroimaging data would lead to a better understanding of the human brain and to better engineer the brain and ultimately toward the enhancement of quality of life.&lt;/p>
&lt;p>BSPL 연구실은 뇌영상 방법들 (MRI, EEG) 등에 다양한 신호처리, 머신러닝, 및 딥러닝 방법들을 접목하여서 인간의 뇌기능을 이해하는 연구를 수행합니다. 대표적인 분석 방법으로는, independent component analysis (ICA), independent vector analysis (IVA), deep neural networks (DNNs) 등을 이용하고 있으며 새로운 아이디어를 추가하여 새롭게 개발하고 있습니다.&lt;/p>
&lt;p>이러한 분석 방법을 뇌영상 데이터에 접목하여서, 인간의 뇌기능을 이해하고자 하며, 이를 바탕으로 뇌기능의 정량적 측정, 뇌기능 자동분류, 뇌기능 향상, 뇌기능 이상의 조기 진단 및 예후 예측 등의 연구를 수행하고, 이를 바탕으로 궁극적으로 인간의 삶의 질 향상을 위한 목표를 갖고 있습니다.&lt;/p></description></item><item><title>Contact Us</title><link>https://bspl.korea.ac.kr/contact/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/contact/</guid><description>&lt;div class="text-center ">
&lt;h2 id="605-science-library-korea-university">605, SCIENCE LIBRARY, KOREA UNIVERSITY&lt;/h2>
&lt;/div>
&lt;div style="text-align: center">
&lt;iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d3161.733316629538!2d127.02648500000001!3d37.584897!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x0%3A0x21f0604c311dc40d!2sKorea%20University%20Library%20System!5e0!3m2!1sen!2skr!4v1625813800677!5m2!1sen!2skr" width="600" height="450" style="border:0; margin:0 auto;" allowfullscreen="" loading="lazy">&lt;/iframe>
&lt;/div>
&lt;br/>
&lt;div class="container">
&lt;div class="row">
&lt;div class="col">
&lt;div dir="ltr">&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;b style="color:rgb(7,55,99);line-height:1.5;background-color:transparent">&lt;font size="4">&lt;br>&lt;/font>&lt;/b>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;b style="color:rgb(7,55,99);line-height:1.5;background-color:transparent">&lt;font size="4">&lt;br>&lt;/font>&lt;/b>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;b style="color:rgb(7,55,99);line-height:1.5;background-color:transparent">&lt;font size="4">고려대학교 뇌신호처리 연구실&lt;/font>&lt;/b>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font size="4">&lt;b>&lt;span style="color:rgb(7,55,99);background-color:transparent">Brain Signal Processing Lab&lt;/span>&lt;/b>&lt;/font>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;b style="font-size:large;line-height:1.5;background-color:transparent">&lt;span style="color:rgb(7,55,99);background-color:transparent">Dept. of BCE, Korea University&lt;/span>&lt;/b>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;br>&lt;/div>&lt;blockquote style="margin:0 0 0 40px;border:none;padding:0px">&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font color="#45818e" size="3">Address:&lt;/font>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;span style="line-height:1.5;background-color:transparent">&lt;font size="3">Room 605, Science Library, Korea University&lt;/font>&lt;/span>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;span style="line-height:1.5;background-color:transparent">&lt;font size="3">145 Anam-ro, Seongbuk-gu, Seoul&amp;nbsp;02841&lt;/font>&lt;/span>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font size="3">&lt;font color="#45818e">Phone:&lt;/font>&amp;nbsp;+82-2-3290-3667&lt;/font>&lt;/div>&lt;/blockquote>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font color="#45818e" style="font-size:medium">E-mail:&lt;/font>&lt;span style="font-size:medium">&amp;nbsp;&lt;/span>&lt;span style="color:rgb(131,94,165);font-size:medium;background-color:transparent">bsplku605 at gmail dot com&lt;/span>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font size="3">&lt;br>&lt;/font>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font size="3">&lt;br>&lt;/font>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font size="3">&lt;br>&lt;/font>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font size="3">&lt;br>&lt;/font>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font size="3">&lt;br>&lt;/font>&lt;/div>&lt;div style="color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;/div>&lt;/div>
&lt;/div>
&lt;div class="col">
&lt;div dir="ltr">&lt;div style="color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font color="#073763" size="4">&lt;b>&lt;br>&lt;/b>&lt;/font>&lt;/div>&lt;div style="color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font color="#073763" size="4">&lt;b>&lt;br>&lt;/b>&lt;/font>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font color="#073763" size="4">&lt;b>이종환 교수 연구실&lt;/b>&lt;/font>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;b style="color:rgb(7,55,99);font-size:large;line-height:1.5;background-color:transparent">Prof. Jong-Hwan Lee's Office&lt;/b>&lt;/div>&lt;div style="text-align:center;font-family:trebuchet ms,sans-serif">&lt;br>&lt;/div>&lt;blockquote style="margin:0 0 0 40px;border:none;padding:0px">&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font color="#45818e" size="3">Address:&lt;/font>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;span style="line-height:1.5;background-color:transparent">&lt;font size="3">Room 604D, Science Library, Korea University&lt;/font>&lt;/span>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font size="3">145 Anam-ro, Seongbuk-gu, Seoul&amp;nbsp;02841&lt;/font>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font size="3">&lt;font color="#45818e">Phone:&lt;/font>&amp;nbsp;&lt;font color="#0b5394">+82-2-3290-5922&lt;/font>&lt;/font>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font size="3">&lt;font color="#45818e">E-mail:&lt;/font>&amp;nbsp;&lt;font color="#3d85c6" style="color:rgb(131,94,165)">jonghwan_lee at korea dot ac dot kr&amp;nbsp;&lt;/font>&lt;/font>&lt;/div>&lt;div style="text-align:center;color:rgb(0,57,101);font-family:trebuchet ms,sans-serif">&lt;font size="3">&lt;font color="#3d85c6" style="color:rgb(131,94,165)">jhlee.jonghwanlee at gmail dot com&amp;nbsp;&lt;/font>&lt;/font>&lt;/div>&lt;/blockquote>&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>DNN (Deep Neural Network)</title><link>https://bspl.korea.ac.kr/softwares/dnn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/softwares/dnn/</guid><description>&lt;p>Deep neural network (DNN) with weight sparsity control (i.e., L1-norm regularization) improved the classification performance using whole-brain resting-state functional connectivity patterns of schizophrenia patient and healthy groups. Initializing DNN&amp;rsquo;s weights through stacked auto-encoder enhanced the classification performance as well. (Kim et al., NI, 2016). Here, we provide MATLAB and Python based codes in terms of the DNN with the weight sparsity control
(&lt;a href="http://bspl.korea.ac.kr/DNN_weightsparsity_MATLAB.zip" target="_blank" rel="noopener">MATLAB code&lt;/a> / &lt;a href="http://bspl.korea.ac.kr/DNN_weightsparsity_python.zip" target="_blank" rel="noopener">Python code&lt;/a> download).&lt;/p>
&lt;p>&lt;strong>Reference&lt;/strong>: Kim et al., Deep neural network with weight sparsity control and pre-training extracts hierarchical features and enhances classification performance: Evidence from whole-brain resting-state functional connectivity patterns of schizophrenia. NeuroImage. 2016 Jan.; 124(Pt A):127-46.
[ &lt;a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=Deep&amp;#43;neural&amp;#43;network&amp;#43;with&amp;#43;weight&amp;#43;sparsity&amp;#43;control&amp;#43;and&amp;#43;pre-training&amp;#43;extracts&amp;#43;hierarchical&amp;#43;features&amp;#43;and&amp;#43;enhances&amp;#43;classification&amp;#43;performance%3A&amp;#43;Evidence&amp;#43;from&amp;#43;whole-brain&amp;#43;resting-state&amp;#43;functional&amp;#43;connectivity&amp;#43;patterns&amp;#43;of&amp;#43;schizophrenia" target="_blank" rel="noopener">PubMed&lt;/a> /
&lt;a href="https://scholar.google.co.kr/scholar?q=Kim&amp;#43;J%2C&amp;#43;Calhoun&amp;#43;VD%2C&amp;#43;Shim&amp;#43;E%2C&amp;#43;Lee&amp;#43;JH*%2C&amp;#43;Deep&amp;#43;neural&amp;#43;network&amp;#43;with&amp;#43;weight&amp;#43;sparsity&amp;#43;control&amp;#43;and&amp;#43;pre-training&amp;#43;extracts&amp;#43;hierarchical&amp;#43;features&amp;#43;and&amp;#43;enhances&amp;#43;classification&amp;#43;performance%3A&amp;#43;Evidence&amp;#43;from&amp;#43;whole-brain&amp;#43;resting-state&amp;#43;functional&amp;#43;connectivity&amp;#43;patterns&amp;#43;of&amp;#43;schizophrenia%2C&amp;#43;Neuroimage.&amp;#43;2016&amp;#43;Jan&amp;#43;1%3B124%28Pt&amp;#43;A%29%3A127-46.&amp;#43;doi%3A&amp;#43;10.1016%2Fj.neuroimage.2015.05.018.&amp;#43;Epub&amp;#43;2015&amp;#43;May&amp;#43;15.&amp;#43;&amp;amp;btnG=&amp;amp;hl=en&amp;amp;as_sdt=0%2C5" target="_blank" rel="noopener">Google Scholar&lt;/a> ]&lt;/p>
&lt;h4 id="matlab-code-downloadhttpbsplkoreaackrdnn_weightsparsity_matlabzip">MATLAB code (&lt;a href="http://bspl.korea.ac.kr/DNN_weightsparsity_MATLAB.zip" target="_blank" rel="noopener">download&lt;/a>)&lt;/h4>
&lt;p>Steps:&lt;/p>
&lt;ol>
&lt;li>Download the MATLAB code as the above link&lt;/li>
&lt;li>Open &amp;ldquo;test_WeightSparsity.m&amp;rdquo; file and prepare/load your own data&lt;/li>
&lt;li>Divide your own data into training and test data set (i.e. &amp;lsquo;train_x&amp;rsquo;, &amp;lsquo;train_y&amp;rsquo;, &amp;lsquo;test_x&amp;rsquo;, &amp;lsquo;test_y&amp;rsquo;)&lt;/li>
&lt;li>Determine how many hidden layers/nodes we are going to use&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>If you have two classes and want to use two hidden layers with 100 nodes, you can set as the following:&lt;/p>
&lt;blockquote>
&lt;p>&amp;gt;&amp;gt; nn = nnsetup([784 100 100 2]);&lt;/p>
&lt;/blockquote>
&lt;/blockquote>
&lt;ol start="5">
&lt;li>Set the target weight sparsity levels at each layer (e.g. nn.nzr = [0.2 0.2]) and other parameters (e.g. learning rate, batch size etc.).&lt;/li>
&lt;li>Run &amp;lsquo;test_WeightSparsity.m&amp;rsquo;.&lt;/li>
&lt;li>Make sure the convergence of the weight sparsity level to the target level for each hidden layer&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>The MATLAB codes were modified from the DeepLearnToolbox to apply non-zero ratio for weight sparsity control.&lt;/p>
&lt;/blockquote>
&lt;h4 id="python-code-downloadhttpbsplkoreaackrdnn_weightsparsity_pythonzip">Python code (&lt;a href="http://bspl.korea.ac.kr/DNN_weightsparsity_python.zip" target="_blank" rel="noopener">download&lt;/a>)&lt;/h4>
&lt;p>Steps:&lt;/p>
&lt;ol>
&lt;li>Download the MNIST data from the link&lt;/li>
&lt;li>Set parameters (e.g., learning rate, regularization term, etc.)in the &amp;ldquo;mlp_h3.py&amp;rdquo; code&lt;/li>
&lt;li>Run the python code using &amp;ldquo;mlp_h3.py&amp;rdquo;&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>The Python codes were modified from the DeepLearningTutorials to apply non-zero ratio for weight sparsity control.&lt;/p>
&lt;/blockquote>
&lt;p>For any questions or comments, please contact Jong-Hwan Lee (&lt;a href="mailto:jonghwan_lee@korea.ac.kr">jonghwan_lee@korea.ac.kr&lt;/a>), Hyun-Chul Kim (&lt;a href="mailto:hyunchul_kim@korea.ac.kr">hyunchul_kim@korea.ac.kr&lt;/a>) or Hojin Jang (&lt;a href="mailto:hojin4671@gmail.com">hojin4671@gmail.com&lt;/a>).&lt;/p>
&lt;p>Please also check out our &lt;a href="https://github.com/bsplku/dnnwsp" target="_blank" rel="noopener">github&lt;/a>!&lt;/p></description></item><item><title>ENV (Eye-tracking based Naturalistic Viewing Paradigm)</title><link>https://bspl.korea.ac.kr/softwares/env/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/softwares/env/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/Software/ENV/env.png" alt="ENV" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>&lt;strong>Reference&lt;/strong>: A naturalistic viewing paradigm using 360° panoramic video clips and real-time field-of-view changes with eye-gaze tracking, NeuroImage, Vol. 216, 2020
[&lt;a href="https://pubmed.ncbi.nlm.nih.gov/32057996/" target="_blank" rel="noopener">PubMed&lt;/a> /
&lt;a href="https://scholar.google.com/scholar?hl=en&amp;amp;as_sdt=0%2C5&amp;amp;q=A&amp;#43;naturalistic&amp;#43;viewing&amp;#43;paradigm&amp;#43;using&amp;#43;360%C2%B0&amp;#43;panoramic&amp;#43;video&amp;#43;clips&amp;#43;and&amp;#43;real-time&amp;#43;field-of-view&amp;#43;changes&amp;#43;with&amp;#43;eye-gaze&amp;#43;tracking&amp;amp;btnG=" target="_blank" rel="noopener">Google Scholar&lt;/a>]&lt;/p>
&lt;p>&lt;a href="https://github.com/bsplku/ENV" target="_blank" rel="noopener">Github&lt;/a>&lt;/p></description></item><item><title>iDR (Iterative Duel-Regression)</title><link>https://bspl.korea.ac.kr/softwares/idr/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/softwares/idr/</guid><description>&lt;p>Iterative Dual-Regression (iDR) with sparse prior is aimed to better estimate an individual&amp;rsquo;s neuronal activation using the results of an independent component analysis (ICA) method applied to a temporally concatenated group of fMRI data (i.e., Tc-GICA method)
(&lt;a href="http://www.nitrc.org/projects/iterdrwsp" target="_blank" rel="noopener">Download&lt;/a>).&lt;/p>
&lt;p>&lt;strong>Reference&lt;/strong>: Kim et al., Iterative approach of dual regression with a sparse prior enhances the performance of independent component analysis for group functional magnetic resonance imaging (fMRI) data, NeuroImage 2012, 63 (4): 1864-89.
[ &lt;a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=Iterative&amp;#43;approach&amp;#43;of&amp;#43;dual&amp;#43;regression&amp;#43;with&amp;#43;a&amp;#43;sparse&amp;#43;prior&amp;#43;enhances&amp;#43;the&amp;#43;performance&amp;#43;of&amp;#43;independent&amp;#43;component&amp;#43;analysis&amp;#43;for&amp;#43;group&amp;#43;functional&amp;#43;magnetic&amp;#43;resonance&amp;#43;imaging&amp;#43;%28fMRI%29&amp;#43;data" target="_blank" rel="noopener">PubMed&lt;/a> /
&lt;a href="https://scholar.google.com/scholar?q=Iterative&amp;#43;approach&amp;#43;of&amp;#43;dual&amp;#43;regression&amp;#43;with&amp;#43;a&amp;#43;sparse&amp;#43;prior&amp;#43;enhances&amp;#43;the&amp;#43;performance&amp;#43;of&amp;#43;independent&amp;#43;component&amp;#43;analysis&amp;#43;for&amp;#43;group&amp;#43;functional&amp;#43;magnetic&amp;#43;resonance&amp;#43;imaging&amp;#43;%28fMRI%29&amp;#43;data&amp;amp;btnG=&amp;amp;hl=en&amp;amp;lr=lang_en&amp;amp;as_sdt=0%2C5" target="_blank" rel="noopener">Google Scholar&lt;/a> ]&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/Software/IDR/iDR2.png" alt="IDR" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p style="text-align: center">&lt;a href="https://www.nitrc.org/projects/iterdrwsp/">iterdrwsp&lt;/a>&lt;/p>
&lt;p>For any questions or comments, please contact Jong-Hwan Lee (&lt;a href="mailto:jonghwan_lee@korea.ac.kr">jonghwan_lee@korea.ac.kr&lt;/a>) or Yong-Hwan Kim (&lt;a href="mailto:whiteneng@gmail.com">whiteneng@gmail.com&lt;/a>).&lt;/p></description></item><item><title>Members</title><link>https://bspl.korea.ac.kr/members/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/members/</guid><description>&lt;details class="toc-inpage d-print-none " open>
&lt;summary class="font-weight-bold">Table of Contents&lt;/summary>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#faculty">Faculty&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#jong-hwan-lee-phd">Jong-Hwan Lee, Ph.D.&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#phd-candidates-and-integrated-ms-phd-candidates">PhD Candidates and Integrated MS-PhD Candidates&lt;/a>&lt;/li>
&lt;li>&lt;a href="#ms-candidates">MS Candidates&lt;/a>&lt;/li>
&lt;li>&lt;a href="#researchers">Researchers&lt;/a>&lt;/li>
&lt;li>&lt;a href="#lab-manager">Lab Manager&lt;/a>&lt;/li>
&lt;li>&lt;a href="#alumni">Alumni&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#graduate-students">Graduate students&lt;/a>&lt;/li>
&lt;li>&lt;a href="#researchers-and-research-assistants">Researchers and Research Assistants&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/details>
&lt;h2 id="faculty">Faculty&lt;/h2>
&lt;h3 id="jong-hwan-lee-phd">Jong-Hwan Lee, Ph.D.&lt;/h3>
&lt;!-- ![Professor](//bspl.korea.ac.kr/image/bspl/JHLee_21Jul.png) -->
&lt;img src='https://bspl.korea.ac.kr/image/bspl/JHLee_21Jul.png' width=850>
&lt;p>My longstanding research interests have been in the investigation of hidden information underlying sensory signals and development of efficient methods for accurate analysis of this information. My recent research has focused on the application of the artificial neural networks and/or machine learning algorithms to the neuroimaging data, such as structural MRI (sMRI), functional MRI (fMRI), and electroencephalography (EEG). In our lab, we have been working on the studies/projects such as (i) a novel application of independent vector analysis and (ii) an iterative approach of dual-regression with sparse constraints on spatial patterns of neuronal activations applying to group fMRI data processing, (iii) automated classification of thought processes measured via fMRI data, (iv) analysis of simultaneous EEG-fMRI methods and their applications to sleep-onset/epileptic-foci detection and to denoising of cryogenic pump artifact of MRI scanner, (v) real-time fMRI based neurofeedback, (vi) nicotine addiction research via neuroimaging, and (vii) an early diagnosis of neurodegenerative and/or neuropsychiatric diseases from multimodal neuroimaging using advanced methods such as deep learning/machine learning and representational similarity analysis.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/KDY.png" alt="KDY" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>My previous researches were (1) to measure the features from the resting-state fMRI, (2) to examine the feasibility of modulating brain activation/connectivity via real-time fMRI neurofeedback on heavy smokers, and (3) to investigate where the brain regions are activated during the decision-making process depending on the reasoning orders. The current interest-of-researches are (1) to apply the real-time fMRI neurofeedback with a new framework to the diverse domain such as smoking addiction, social interaction, rehabilitation, and multimodality and (2) to evaluate the neuroimaging data using several methods such as GLM, ICA, RSA, MVPA, etc.&lt;/p>
&lt;p>&lt;br />&lt;/p>
&lt;h2 id="phd-candidates-and-integrated-ms-phd-candidates">PhD Candidates and Integrated MS-PhD Candidates&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/Hanh.png" alt="Hanh" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>My interest in research is developing new analysis methods based on the interdisciplinary studies of brain signal processing and the cognitive processes, especially applying Machine learning algorithms and Deep learning techniques to the EEG and fMRI data analysis.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/LJHyeon%282%29.jpg" alt="LJH" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>One of my research aims is to discover individual distinctiveness in dynamic functional connectivity. I am also investigating how information (e.g., text/language) is processed in the brain. Mostly, I utilize deep learning and machine learning techniques for the analysis.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/LCH.png" alt="LCH" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>I&amp;rsquo;m interested in developing algorithms to figure out how cognitive processes work by using fMRI data.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/SSY.png" alt="SSY" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>I am trying to find links between neuroscience and deep learning. My research topics are mainly focused on how techniques from deep learning (such as attention mechanism) are related to the patterns of brain activity, and how the information from brain signal data can be applied to construct deep learning models.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/HJW.png" alt="HJW" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>My research interest is to help patients of mental disorders such as depression and schizophrenia by utilizing deep learning.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/PMJ.png" alt="PMJ" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>My researcher interest is neuroplasticity algorithms for brain diseases (stroke) with fmri.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/CMS.png" alt="CMS" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>My research interest is image signal processing with deep-learning and neuroplasticity algorithms for brain diseases with fMRI.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/KJE.png" alt="KJE" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>I am interested in Emotion processing with deep-learning and neuroplasticity algorithms for brain diseases with fMRI.&lt;/p>
&lt;p>&lt;br />&lt;/p>
&lt;h2 id="ms-candidates">MS Candidates&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/JMY.png" alt="JMY" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>I&amp;rsquo;m interested in the relevance between brain and computational model expecting complementary insight on both domains. Mostly, I investigate visual information processing and utilize Deep Neural Networks(DNNs), especially CNNs, for the analysis.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/KYJ.png" alt="KYJ" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>I am interested in Audio signal processing and Emotion processing with fMRI-EEG.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/HJD.png" alt="HJD" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>I&amp;rsquo;m interested in early diagnosis of several psychiatric disorders such as depression, bipolar disorder, to treat them in early stage.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/JYJ.png" alt="JYJ" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>I am interested in human decision making and how individual&amp;rsquo;s psychopathological symptoms affects one&amp;rsquo;s choice by using EEG-fmri.&lt;/p>
&lt;p>&lt;br />&lt;/p>
&lt;h2 id="researchers">Researchers&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/JSM.png" alt="JSM" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>I am interested in observing the brain when vaping the E-cigarette through real-time fMRI. Through this study, I want to know brain regions responding to nicotine and how they are affected by nicotine.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/JSS.png" alt="JSS" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>I am interested in brain mechanisms of recognizing objects and learning complex behaviors. Current research aims are (1) designing a non-fMRI, web-based behavioral experimental framework, and (2) utilizing a VR-like environment to study reinforcement learnings in human participants.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/JSH.png" alt="JSH" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>I am interested in integrating genetics and brain imaging for mental disorders.&lt;/p>
&lt;p>&lt;br />&lt;/p>
&lt;h2 id="lab-manager">Lab Manager&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="//bspl.korea.ac.kr/image/bspl/JHK.png" alt="KJH" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>&lt;br />&lt;/p>
&lt;h2 id="alumni">Alumni&lt;/h2>
&lt;h3 id="graduate-students">Graduate students&lt;/h3>
&lt;p>&lt;strong>Dong-Youl Kim, Ph.D., Feb/2021&lt;/strong> &lt;br />
Research Professor, Korea University&lt;/p>
&lt;p>&lt;strong>Niv Lustig, M.S., Aug/2020&lt;/strong> &lt;br />
Currently job searching in Israel&lt;/p>
&lt;p>&lt;strong>Sungman Jo, M.S., Aug/2020&lt;/strong> &lt;br />
Currently Researcher at Brain Engineering Institute, Korea University&lt;/p>
&lt;p>&lt;strong>Hyun-Chul Kim, Ph.D., Feb/2019&lt;/strong> &lt;br />
Research Fellow, Brigham and Women&amp;rsquo;s Hospital, Harvard Medical School, Boston&lt;/p>
&lt;p>&lt;strong>DaWoon Heo, M.S. Feb/2018&lt;/strong> &lt;br />
Researcher at KIST&lt;/p>
&lt;p>&lt;strong>Wan-Joo Park, Ph. D., Aug/2016&lt;/strong> &lt;br />
Currently Post-Doctoral Associate at Engineering Division, NYU Abu Dhabi&lt;/p>
&lt;p>&lt;strong>Hojin Jang, M.S. Aug/2016&lt;/strong> &lt;br />
Currently Ph.D. candidate at Vanderbilt University&lt;/p>
&lt;p>&lt;strong>Suji Kim, M.S. Aug/2016&lt;/strong> &lt;br />
Currently working at a start-up&lt;/p>
&lt;p>&lt;strong>Junghoe Kim, Ph. D., Feb/2016&lt;/strong> &lt;br />
Currently at the Samsung Electronics, Inc.&lt;/p>
&lt;p>&lt;strong>Hojung Kang, M.S. Aug/2013&lt;/strong> &lt;br />
Currently at the Korea Institute of Brain Science&lt;/p>
&lt;p>&lt;strong>Yong-Hwan Kim, M.S. Feb/2012&lt;/strong> &lt;br />
Currently at the ASAN Medical Center&lt;/p>
&lt;p>&lt;strong>Dong-Youl Kim, M.S. Aug/2011&lt;/strong> &lt;br />
Currently at BSPL as a Ph.D. candidate&lt;/p>
&lt;p>&lt;strong>Eun Kyung Jung, M.A.&lt;/strong> &lt;br />
Completed Ph.D. coursework&lt;/p>
&lt;p>&lt;strong>Han-Gil Lee&lt;/strong> &lt;br />
Completed MS coursework&lt;/p>
&lt;p>&lt;strong>Minkyung Oh&lt;/strong> &lt;br />
Completed MS coursework&lt;/p>
&lt;p>&lt;strong>Wangwon Lee&lt;/strong> &lt;br />
Completed MS coursework&lt;/p>
&lt;p>&lt;br />&lt;/p>
&lt;h3 id="researchers-and-research-assistants">Researchers and Research Assistants&lt;/h3>
&lt;p>&lt;strong>JunDong Hwang (July/2020 - Feb/2021)&lt;/strong> &lt;br />
School of Life Sciences, Korea University&lt;/p>
&lt;p>&lt;strong>Niv Lustig (Sep/2020 - Dec/2020)&lt;/strong> &lt;br />
Brain Engineering Institute, Korea University&lt;/p>
&lt;p>&lt;strong>Jihyeok Jeong (June/2020 - Oct/2020)&lt;/strong> &lt;br />
&lt;strong>Naewoo Shin (June/2019-April/2020)&lt;/strong> &lt;br />
&lt;strong>Hye-In Gu (Sep/2019-Feb/2020)&lt;/strong> &lt;br />
Department of Statistics, Korea University&lt;/p>
&lt;p>&lt;strong>Jae-Ryong So (Sep/2019- Nov/2019)&lt;/strong> &lt;br />
Devision of Industrial Management Engineering, College of Engineering, Korea University&lt;/p>
&lt;p>&lt;strong>SeungA Kim (Winter/2018- Nov/2019)&lt;/strong> &lt;br />
Department of Chemistry, Korea University&lt;/p>
&lt;p>&lt;strong>Sung-Jun Lee (Winter/2018- Nov/2019)&lt;/strong> &lt;br />
Department of Architecture, Korea University&lt;/p>
&lt;p>&lt;strong>Soo-Jong Kim, M.S.(Jul. 2019 - Sep. 2019)&lt;/strong> &lt;br />&lt;/p>
&lt;p>&lt;strong>Junho Yun, B.A(Jan. 2019 - Sep. 2019)&lt;/strong> &lt;br />&lt;/p>
&lt;p>&lt;strong>Seok-Hyun Seo (January/2019- May/2019)&lt;/strong> &lt;br />
Department of Statistics, Korea University&lt;/p>
&lt;p>&lt;strong>Hye-Song An, B.A. (April/2019 - July/2019)&lt;/strong> &lt;br />
Currently at the Job market&lt;/p>
&lt;p>&lt;strong>Inuk Song, M.S. (Apr. 2019 - Jun. 2019)&lt;/strong> &lt;br />
Currently preparing a Ph.D. program&lt;/p>
&lt;p>&lt;strong>Gyuhyun Kim (Jan. 2019 - Feb. 2019)&lt;/strong> &lt;br />
Currently at Mokwon University&lt;/p>
&lt;p>&lt;strong>Jinsu Kim (Mar/2018 - Feb/2019)&lt;/strong> &lt;br />&lt;/p>
&lt;p>&lt;strong>Jaehun Shim (Nov. 2017 - Nov. 2018)&lt;/strong> &lt;br />
Currently at the College of Liberal Arts, Korea University&lt;/p>
&lt;p>&lt;strong>Jungwoon Yang (Nov. 2017 - Aug. 2018)&lt;/strong> &lt;br />
Currently at Graduate School of Education, Korea University&lt;/p>
&lt;p>&lt;strong>Sunwoo Nam (Nov. 2017 - Feb. 2018)&lt;/strong> &lt;br />
Currently at Graduate School of Medicine&lt;/p>
&lt;p>&lt;strong>Hanh Vu, M.S. (Dec. 2017 - Aug. 2018)&lt;/strong> &lt;br />
Bio-Engineering, Pohang University of Science and Technology (POSTECH) &lt;br />
Currently a Ph. D. candidate at the BSPL, Department of Brain and Cognitive Engineering, Korea University&lt;/p>
&lt;p>&lt;strong>Jérémy Julien (Fall/2015)&lt;/strong> &lt;br />
VR &amp;amp; Health R&amp;amp;D Engineer Intern Sssilor, France&lt;/p>
&lt;p>&lt;strong>Taewoon Kim (Summer/2014)&lt;/strong> &lt;br />
School of Electrical &amp;amp; Electronic Engineering, Yonsei Univ. &lt;br />
Currently at Dept of Information and Communication Systems, TUHH, Hamburg, Germany&lt;/p>
&lt;p>&lt;strong>Yujin Jang (Fall/2013)&lt;/strong> &lt;br />
College of Liberal arts, Korea Univ. &lt;br />
Currently at Dept. of Psychology, Korea University&lt;/p>
&lt;p>&lt;strong>Do-Ran Hwang (Fall/2013)&lt;/strong> &lt;br />
College of Liberal arts, Korea Univ. &lt;br />
Currently at Law School, Seoul National University&lt;/p>
&lt;p>&lt;strong>Kyoung-Ran Chi (Fall/2013)&lt;/strong> &lt;br />
College of Science, Korea Univ.&lt;/p>
&lt;p>&lt;strong>Aram Kim (Fall/2013)&lt;/strong> &lt;br />
College of Information and Technology, Korea Univ.&lt;/p>
&lt;p>&lt;strong>JaeHeon Jeong (Fall/2011 - Fall/2012)&lt;/strong> &lt;br />
College of Information and Technology, Korea Univ.&lt;/p>
&lt;p>&lt;strong>MinJoong Kim (Fall/2011)&lt;/strong> &lt;br />
College of Information and Technology, Korea Univ.&lt;/p>
&lt;p>&lt;strong>Ji-Hye Jang (Winter/2010 - Spring/2011)&lt;/strong> &lt;br />
College of Information and Technology, Korea Univ. &lt;br />
Currently a Ph.D. candidate at TU München, München&lt;/p>
&lt;p>&lt;strong>Jin-Sung Lee (Spring/2011)&lt;/strong> &lt;br />
College of Information and Technology, Korea Univ.&lt;/p>
&lt;p>&lt;strong>Su-Hyun Ha (Spring/2010 - Winter/2010)&lt;/strong> &lt;br />
College of Information and Technology, Korea Univ. &lt;br />
Currently at KAIST&lt;/p>
&lt;p>&lt;strong>Hyuk-Soo Shin (Fall/2010)&lt;/strong> &lt;br />
College of Information and Technology, Korea Univ. &lt;br />
Currently at CIC, Korea University&lt;/p>
&lt;p>&lt;strong>Jongmin Lee (Fall/2010)&lt;/strong> &lt;br />
College of Information and Technology, Korea Univ. &lt;br />
Currently at CIC, Korea University&lt;/p>
&lt;p>&lt;strong>Heon Lee (Fall/2010)&lt;/strong> &lt;br />
College of Information and Technology, Korea Univ.&lt;/p>
&lt;p>&lt;strong>Seongmin Kim (July/2015-Aug/2015)&lt;/strong> &lt;br />&lt;/p>
&lt;p>&lt;strong>Deuk-Won Seo (Feb/2015-Mar/2015)&lt;/strong> &lt;br />&lt;/p>
&lt;p>&lt;strong>Nam-Jun Kim (Sep/2014-Dec/2014)&lt;/strong> &lt;br />
&lt;strong>Chang-Ju Yoon (Mar/2012-Aug/2012)&lt;/strong> &lt;br />
&lt;strong>Kangmin Lee (Feb/2013-Mar/2013)&lt;/strong>&lt;/p></description></item><item><title>rsPCA</title><link>https://bspl.korea.ac.kr/softwares/rspca/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bspl.korea.ac.kr/softwares/rspca/</guid><description>&lt;p>Recursive approach of EEG-segment-based principal component analysis (rsPCA) toolbox to eliminate helium-pump artifact in EEG data that were simultaneously acquired with fMRI data
(&lt;a href="http://bspl.korea.ac.kr/rspca.zip" target="_blank" rel="noopener">Download&lt;/a>/&lt;a href="https://github.com/rsPCA/rspcacode" target="_blank" rel="noopener">GitHub&lt;/a>).&lt;/p>
&lt;p>&lt;strong>Reference&lt;/strong>: Kim et al., Recursive approach of EEG segment based principal component analysis substantially reduces helium-pump artifacts of EEG data simultaneously acquired with fMRI, NeuroImage 2015, 104: 437-51
[ &lt;a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=Recursive&amp;#43;approach&amp;#43;of&amp;#43;EEG&amp;#43;segment&amp;#43;based&amp;#43;principal&amp;#43;component&amp;#43;analysis&amp;#43;substantially&amp;#43;reduces&amp;#43;helium-pump&amp;#43;artifacts&amp;#43;of&amp;#43;EEG&amp;#43;data&amp;#43;simultaneously&amp;#43;acquired&amp;#43;with&amp;#43;fMRI" target="_blank" rel="noopener">PubMed&lt;/a> /
&lt;a href="https://scholar.google.com/scholar?q=Recursive&amp;#43;approach&amp;#43;of&amp;#43;EEG&amp;#43;segment&amp;#43;based&amp;#43;principal&amp;#43;component&amp;#43;analysis&amp;#43;substantially&amp;#43;reduces&amp;#43;helium-pump&amp;#43;artifacts&amp;#43;of&amp;#43;EEG&amp;#43;data&amp;#43;simultaneously&amp;#43;acquired&amp;#43;with&amp;#43;fMRI&amp;amp;btnG=&amp;amp;hl=en&amp;amp;lr=lang_en&amp;amp;as_sdt=0%2C5" target="_blank" rel="noopener">Google Scholar&lt;/a> ]&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://sites.google.com/site/bsplkoreauniversity/_/rsrc/1625602887601/software/rspca/main_rspca.png?height=232&amp;amp;width=400" alt="rsPCA" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>For any questions or comments, please contact Jong-Hwan Lee (&lt;a href="mailto:jonghwan_lee@korea.ac.kr">jonghwan_lee@korea.ac.kr&lt;/a>) or Hyun-Chul Kim (&lt;a href="mailto:hyunchul_kim@korea.ac.kr">hyunchul_kim@korea.ac.kr&lt;/a>).&lt;/p></description></item></channel></rss>